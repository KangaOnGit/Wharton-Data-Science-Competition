{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eeb3635",
   "metadata": {
    "papermill": {
     "duration": 0.007245,
     "end_time": "2025-02-18T17:48:40.362261",
     "exception": false,
     "start_time": "2025-02-18T17:48:40.355016",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03c6fc07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:48:40.374340Z",
     "iopub.status.busy": "2025-02-18T17:48:40.374083Z",
     "iopub.status.idle": "2025-02-18T17:48:45.200632Z",
     "shell.execute_reply": "2025-02-18T17:48:45.199667Z"
    },
    "papermill": {
     "duration": 4.835019,
     "end_time": "2025-02-18T17:48:45.203002",
     "exception": false,
     "start_time": "2025-02-18T17:48:40.367983",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (1.0.12)\r\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.5.1+cu121)\r\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.1+cu121)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.2)\r\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.27.0)\r\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.5)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.16.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2024.9.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.2)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.67.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.12.2)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.26.4)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (11.0.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (3.0.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision->timm) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision->timm) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision->timm) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision->timm) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision->timm) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision->timm) (2.4.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.4.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.12.14)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision->timm) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision->timm) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torchvision->timm) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torchvision->timm) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torchvision->timm) (2024.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b0e0cba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:48:45.217061Z",
     "iopub.status.busy": "2025-02-18T17:48:45.216780Z",
     "iopub.status.idle": "2025-02-18T17:48:49.010666Z",
     "shell.execute_reply": "2025-02-18T17:48:49.009777Z"
    },
    "papermill": {
     "duration": 3.802573,
     "end_time": "2025-02-18T17:48:49.012338",
     "exception": false,
     "start_time": "2025-02-18T17:48:45.209765",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\r\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\r\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\r\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.67.1)\r\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\r\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\r\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.27.0)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\r\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.10)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.12.14)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\r\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\r\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: evaluate\r\n",
      "Successfully installed evaluate-0.4.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7619b12",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-18T17:48:49.027377Z",
     "iopub.status.busy": "2025-02-18T17:48:49.027096Z",
     "iopub.status.idle": "2025-02-18T17:49:03.334068Z",
     "shell.execute_reply": "2025-02-18T17:49:03.333102Z"
    },
    "papermill": {
     "duration": 14.316525,
     "end_time": "2025-02-18T17:49:03.335820",
     "exception": false,
     "start_time": "2025-02-18T17:48:49.019295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Processing n' Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Compute\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Random\n",
    "import os\n",
    "import random as rand\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7fc042e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:49:03.349543Z",
     "iopub.status.busy": "2025-02-18T17:49:03.349252Z",
     "iopub.status.idle": "2025-02-18T17:49:03.352923Z",
     "shell.execute_reply": "2025-02-18T17:49:03.352067Z"
    },
    "papermill": {
     "duration": 0.011755,
     "end_time": "2025-02-18T17:49:03.354294",
     "exception": false,
     "start_time": "2025-02-18T17:49:03.342539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a0c64ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:49:03.368736Z",
     "iopub.status.busy": "2025-02-18T17:49:03.368505Z",
     "iopub.status.idle": "2025-02-18T17:49:03.376753Z",
     "shell.execute_reply": "2025-02-18T17:49:03.375912Z"
    },
    "papermill": {
     "duration": 0.01807,
     "end_time": "2025-02-18T17:49:03.378596",
     "exception": false,
     "start_time": "2025-02-18T17:49:03.360526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "  rand.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.cuda.manual_seed(seed)\n",
    "  torch.cuda.manual_seed_all(seed)\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "  torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed = 59\n",
    "set_seed(59)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9a3f76",
   "metadata": {
    "papermill": {
     "duration": 0.006719,
     "end_time": "2025-02-18T17:49:03.393551",
     "exception": false,
     "start_time": "2025-02-18T17:49:03.386832",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "-------------------------\n",
    "# **Data Sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7de0f23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:49:03.415601Z",
     "iopub.status.busy": "2025-02-18T17:49:03.415316Z",
     "iopub.status.idle": "2025-02-18T17:49:03.419348Z",
     "shell.execute_reply": "2025-02-18T17:49:03.418446Z"
    },
    "papermill": {
     "duration": 0.018936,
     "end_time": "2025-02-18T17:49:03.420630",
     "exception": false,
     "start_time": "2025-02-18T17:49:03.401694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = '/kaggle/input/wharton-bkb-dataset/games_2022 (1).xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "036651fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:49:03.438211Z",
     "iopub.status.busy": "2025-02-18T17:49:03.437902Z",
     "iopub.status.idle": "2025-02-18T17:49:09.487987Z",
     "shell.execute_reply": "2025-02-18T17:49:09.486804Z"
    },
    "papermill": {
     "duration": 6.061724,
     "end_time": "2025-02-18T17:49:09.489698",
     "exception": false,
     "start_time": "2025-02-18T17:49:03.427974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Type: <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(data_dir)\n",
    "print(f\"Dataset Type: {type(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20b78fa0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:49:09.503887Z",
     "iopub.status.busy": "2025-02-18T17:49:09.503428Z",
     "iopub.status.idle": "2025-02-18T17:49:09.507162Z",
     "shell.execute_reply": "2025-02-18T17:49:09.506194Z"
    },
    "papermill": {
     "duration": 0.012449,
     "end_time": "2025-02-18T17:49:09.508607",
     "exception": false,
     "start_time": "2025-02-18T17:49:09.496158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_cls = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60277ed6",
   "metadata": {
    "papermill": {
     "duration": 0.006957,
     "end_time": "2025-02-18T17:49:09.522819",
     "exception": false,
     "start_time": "2025-02-18T17:49:09.515862",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "-----------------------------\n",
    "# **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e663dc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:49:09.537679Z",
     "iopub.status.busy": "2025-02-18T17:49:09.537377Z",
     "iopub.status.idle": "2025-02-18T17:49:09.597565Z",
     "shell.execute_reply": "2025-02-18T17:49:09.596477Z"
    },
    "papermill": {
     "duration": 0.069288,
     "end_time": "2025-02-18T17:49:09.598973",
     "exception": false,
     "start_time": "2025-02-18T17:49:09.529685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          game_id  game_date                       team     FGA_2     FGM_2  \\\n",
      "0  game_2022_2011 2021-12-30      georgia_lady_bulldogs  0.661290  0.513514   \n",
      "1  game_2022_2011 2021-12-30                 lsu_tigers  0.661290  0.567568   \n",
      "2  game_2022_2012 2021-12-30            missouri_tigers  0.548387  0.405405   \n",
      "3  game_2022_2012 2021-12-30   south_carolina_gamecocks  0.741935  0.540541   \n",
      "4  game_2022_2013 2021-12-30  tennessee_lady_volunteers  0.516129  0.459459   \n",
      "\n",
      "      FGA_3     FGM_3       FTA    FTM       AST  ...      DREB     OREB  \\\n",
      "0  0.196078  0.227273  0.125000  0.075  0.361111  ...  0.410256  0.34375   \n",
      "1  0.196078  0.181818  0.312500  0.200  0.388889  ...  0.410256  0.34375   \n",
      "2  0.274510  0.318182  0.333333  0.325  0.250000  ...  0.564103  0.18750   \n",
      "3  0.392157  0.272727  0.187500  0.125  0.388889  ...  0.461538  0.62500   \n",
      "4  0.274510  0.181818  0.312500  0.250  0.416667  ...  0.641026  0.37500   \n",
      "\n",
      "   F_tech  F_personal  team_score  opponent_team_score  rest_days  \\\n",
      "0     0.0    0.451613          62                   68   0.210526   \n",
      "1     0.0    0.096774          68                   62   0.052632   \n",
      "2     0.0    0.225806          70                   69   0.184211   \n",
      "3     0.0    0.354839          69                   70   0.210526   \n",
      "4     0.0    0.290323          62                   44   0.052632   \n",
      "\n",
      "   prev_game_dist  home_away_NS  travel_dist  \n",
      "0        0.000000             1     0.000000  \n",
      "1        0.105722             0     0.121105  \n",
      "2        0.047601             1     0.000000  \n",
      "3        0.148063             0     0.169606  \n",
      "4        0.000000             1     0.000000  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "df_cls = df_cls.drop(columns = ['OT_length_min_tot', 'attendance', 'tz_dif_H_E',\n",
    "                        'home_away', 'notD1_incomplete', 'largest_lead'])\n",
    "df_cls = df_cls.dropna()\n",
    "df_cls['home_away_NS'] = df_cls['home_away_NS'].replace({\n",
    "    1: 1, -1: 0, 0: 2\n",
    "})\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# List of columns to normalize\n",
    "stats_to_normalize = ['FGA_2', 'FGM_2', 'FGA_3', 'FGM_3', \n",
    "                      'FTA', 'FTM', 'AST', 'BLK', 'STL', 'TOV', \n",
    "                      'TOV_team', 'DREB', 'OREB', 'F_tech', 'F_personal', \n",
    "                      'rest_days', 'prev_game_dist', 'travel_dist']\n",
    "\n",
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "# Apply MinMaxScaler only to the selected stats\n",
    "df_cls[stats_to_normalize] = scaler.fit_transform(df_cls[stats_to_normalize])\n",
    "\n",
    "print(df_cls.head())  # Check normalized values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ec31ac2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:49:09.613316Z",
     "iopub.status.busy": "2025-02-18T17:49:09.613015Z",
     "iopub.status.idle": "2025-02-18T17:49:09.620102Z",
     "shell.execute_reply": "2025-02-18T17:49:09.619527Z"
    },
    "papermill": {
     "duration": 0.015587,
     "end_time": "2025-02-18T17:49:09.621334",
     "exception": false,
     "start_time": "2025-02-18T17:49:09.605747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def preprocess_data_diff(data):\n",
    "    \n",
    "    \"\"\"\n",
    "    Preprocessed Data (1st Step)\n",
    "        Input: \n",
    "        - data: Dataset File -> csv\n",
    "\n",
    "        Output:\n",
    "        - processed_df: Processed Dataset File -> pd\n",
    "    \"\"\"\n",
    "\n",
    "    epsilon = 1e-8\n",
    "    T = 5 # Temperature\n",
    "    \n",
    "    processed_data = []\n",
    "    \n",
    "    stats_to_diff = [\n",
    "        'FGA_2', 'FGM_2', 'FGA_3', 'FGM_3', 'FTA',\n",
    "        'FTM', 'AST', 'BLK', 'STL', 'TOV', 'TOV_team',\n",
    "        'DREB', 'OREB', 'F_tech', 'F_personal', 'rest_days',\n",
    "        'prev_game_dist', 'travel_dist'\n",
    "    ]\n",
    "    \n",
    "    # Process each game\n",
    "    for game_id in data['game_id'].unique():\n",
    "        game_data = data[data['game_id'] == game_id]\n",
    "\n",
    "        # Ensure the game has exactly 2 teams\n",
    "        if len(game_data) != 2:\n",
    "            print(f\"Skipping game {game_id} due to missing teams.\")\n",
    "            continue\n",
    "\n",
    "        # Extract teams\n",
    "        teamA = game_data.iloc[0]\n",
    "        teamB = game_data.iloc[1]\n",
    "\n",
    "        entry = {\n",
    "            'teamA': teamA['team'],\n",
    "            'teamB': teamB['team'],\n",
    "            'teamA_score': teamA['team_score'],\n",
    "            'teamB_score': teamB['team_score'],\n",
    "\n",
    "            # Embedding for Home/Away/Neutral\n",
    "            'A_H/W/N': teamA['home_away_NS'], \n",
    "            'B_H/W/N': teamB['home_away_NS'],\n",
    "\n",
    "            # 0: Lost | 1: Won | 2: Draw\n",
    "            'W/L/D (teamA)': 0 if teamA['team_score'] < teamB['team_score']\n",
    "                            else 1 if teamA['team_score'] > teamB['team_score']\n",
    "                            else 2\n",
    "        }\n",
    "\n",
    "        # Compute stat differences\n",
    "        for stat in stats_to_diff:\n",
    "            # Handle NA values\n",
    "            if pd.isna(teamB[stat]) and pd.isna(teamA[stat]):\n",
    "                teamA[stat], teamB[stat] = 0, 0\n",
    "                \n",
    "            elif pd.isna(teamA[stat]):\n",
    "                print(f\"Team A ({teamA['team']}) {stat} has NA. Using Team B's value.\")\n",
    "                teamA[stat] = teamB[stat]\n",
    "                \n",
    "            elif pd.isna(teamB[stat]):\n",
    "                print(f\"Team B ({teamB['team']}) {stat} has NA. Using Team A's value.\")\n",
    "                teamB[stat] = teamA[stat]\n",
    "                \n",
    "            # Compute difference\n",
    "            entry[f'{stat}% (A/B)'] = math.tanh((teamA[stat] - teamB[stat] + epsilon) / T)\n",
    "        \n",
    "        processed_data.append(entry)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    processed_df = pd.DataFrame(processed_data)\n",
    "\n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bc71460",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:49:09.635097Z",
     "iopub.status.busy": "2025-02-18T17:49:09.634895Z",
     "iopub.status.idle": "2025-02-18T17:49:18.876994Z",
     "shell.execute_reply": "2025-02-18T17:49:18.875807Z"
    },
    "papermill": {
     "duration": 9.250604,
     "end_time": "2025-02-18T17:49:18.878476",
     "exception": false,
     "start_time": "2025-02-18T17:49:09.627872",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping game game_2022_1320 due to missing teams.\n",
      "Skipping game game_2022_2198 due to missing teams.\n",
      "Skipping game game_2022_2621 due to missing teams.\n",
      "Skipping game game_2022_3347 due to missing teams.\n",
      "Skipping game game_2022_3744 due to missing teams.\n",
      "Skipping game game_2022_4049 due to missing teams.\n",
      "Skipping game game_2022_4745 due to missing teams.\n",
      "Skipping game game_2022_181 due to missing teams.\n",
      "Skipping game game_2022_1994 due to missing teams.\n",
      "Skipping game game_2022_3906 due to missing teams.\n",
      "Skipping game game_2022_4264 due to missing teams.\n",
      "Skipping game game_2022_2441 due to missing teams.\n",
      "Skipping game game_2022_182 due to missing teams.\n",
      "Skipping game game_2022_183 due to missing teams.\n",
      "Skipping game game_2022_219 due to missing teams.\n",
      "Skipping game game_2022_220 due to missing teams.\n",
      "Skipping game game_2022_221 due to missing teams.\n",
      "Skipping game game_2022_222 due to missing teams.\n",
      "Skipping game game_2022_320 due to missing teams.\n",
      "Skipping game game_2022_468 due to missing teams.\n",
      "Skipping game game_2022_531 due to missing teams.\n",
      "Skipping game game_2022_607 due to missing teams.\n",
      "Skipping game game_2022_814 due to missing teams.\n",
      "Skipping game game_2022_1027 due to missing teams.\n",
      "Skipping game game_2022_1331 due to missing teams.\n",
      "Skipping game game_2022_1586 due to missing teams.\n",
      "Skipping game game_2022_2019 due to missing teams.\n",
      "Skipping game game_2022_2126 due to missing teams.\n",
      "Skipping game game_2022_2340 due to missing teams.\n",
      "Skipping game game_2022_2770 due to missing teams.\n",
      "Skipping game game_2022_3322 due to missing teams.\n",
      "Skipping game game_2022_3661 due to missing teams.\n",
      "Skipping game game_2022_3816 due to missing teams.\n",
      "Skipping game game_2022_4166 due to missing teams.\n",
      "Skipping game game_2022_4762 due to missing teams.\n",
      "Skipping game game_2022_2537 due to missing teams.\n",
      "Skipping game game_2022_327 due to missing teams.\n",
      "Skipping game game_2022_155 due to missing teams.\n",
      "Skipping game game_2022_185 due to missing teams.\n",
      "Skipping game game_2022_226 due to missing teams.\n",
      "Skipping game game_2022_423 due to missing teams.\n",
      "Skipping game game_2022_424 due to missing teams.\n",
      "Skipping game game_2022_611 due to missing teams.\n",
      "Skipping game game_2022_688 due to missing teams.\n",
      "Skipping game game_2022_689 due to missing teams.\n",
      "Skipping game game_2022_769 due to missing teams.\n",
      "Skipping game game_2022_771 due to missing teams.\n",
      "Skipping game game_2022_937 due to missing teams.\n",
      "Skipping game game_2022_1196 due to missing teams.\n",
      "Skipping game game_2022_1197 due to missing teams.\n",
      "Skipping game game_2022_1411 due to missing teams.\n",
      "Skipping game game_2022_1590 due to missing teams.\n",
      "Skipping game game_2022_1591 due to missing teams.\n",
      "Skipping game game_2022_1676 due to missing teams.\n",
      "Skipping game game_2022_1677 due to missing teams.\n",
      "Skipping game game_2022_1732 due to missing teams.\n",
      "Skipping game game_2022_2166 due to missing teams.\n",
      "Skipping game game_2022_2167 due to missing teams.\n",
      "Skipping game game_2022_2168 due to missing teams.\n",
      "Skipping game game_2022_2258 due to missing teams.\n",
      "Skipping game game_2022_2259 due to missing teams.\n",
      "Skipping game game_2022_2400 due to missing teams.\n",
      "Skipping game game_2022_2401 due to missing teams.\n",
      "Skipping game game_2022_2715 due to missing teams.\n",
      "Skipping game game_2022_2873 due to missing teams.\n",
      "Skipping game game_2022_2874 due to missing teams.\n",
      "Skipping game game_2022_3440 due to missing teams.\n",
      "Skipping game game_2022_3442 due to missing teams.\n",
      "Skipping game game_2022_3552 due to missing teams.\n",
      "Skipping game game_2022_3555 due to missing teams.\n",
      "Skipping game game_2022_3921 due to missing teams.\n",
      "Skipping game game_2022_4279 due to missing teams.\n",
      "Skipping game game_2022_4531 due to missing teams.\n",
      "Skipping game game_2022_4532 due to missing teams.\n",
      "Skipping game game_2022_272 due to missing teams.\n",
      "Skipping game game_2022_427 due to missing teams.\n",
      "Skipping game game_2022_772 due to missing teams.\n",
      "Skipping game game_2022_1140 due to missing teams.\n",
      "Skipping game game_2022_1510 due to missing teams.\n",
      "Skipping game game_2022_2261 due to missing teams.\n",
      "Skipping game game_2022_2172 due to missing teams.\n",
      "Skipping game game_2022_2979 due to missing teams.\n",
      "Skipping game game_2022_3401 due to missing teams.\n",
      "Skipping game game_2022_4023 due to missing teams.\n",
      "Skipping game game_2022_4477 due to missing teams.\n",
      "Skipping game game_2022_187 due to missing teams.\n",
      "Skipping game game_2022_229 due to missing teams.\n",
      "Skipping game game_2022_231 due to missing teams.\n",
      "Skipping game game_2022_332 due to missing teams.\n",
      "Skipping game game_2022_432 due to missing teams.\n",
      "Skipping game game_2022_536 due to missing teams.\n",
      "Skipping game game_2022_941 due to missing teams.\n",
      "Skipping game game_2022_1201 due to missing teams.\n",
      "Skipping game game_2022_1512 due to missing teams.\n",
      "Skipping game game_2022_1529 due to missing teams.\n",
      "Skipping game game_2022_1533 due to missing teams.\n",
      "Skipping game game_2022_1756 due to missing teams.\n",
      "Skipping game game_2022_1816 due to missing teams.\n",
      "Skipping game game_2022_2549 due to missing teams.\n",
      "Skipping game game_2022_2086 due to missing teams.\n",
      "Skipping game game_2022_189 due to missing teams.\n",
      "Skipping game game_2022_191 due to missing teams.\n",
      "Skipping game game_2022_281 due to missing teams.\n",
      "Skipping game game_2022_283 due to missing teams.\n",
      "Skipping game game_2022_333 due to missing teams.\n",
      "Skipping game game_2022_619 due to missing teams.\n",
      "Skipping game game_2022_620 due to missing teams.\n",
      "Skipping game game_2022_699 due to missing teams.\n",
      "Skipping game game_2022_874 due to missing teams.\n",
      "Skipping game game_2022_1235 due to missing teams.\n",
      "Skipping game game_2022_1341 due to missing teams.\n",
      "Skipping game game_2022_1657 due to missing teams.\n",
      "Skipping game game_2022_1680 due to missing teams.\n",
      "Skipping game game_2022_2211 due to missing teams.\n",
      "Skipping game game_2022_2270 due to missing teams.\n",
      "Skipping game game_2022_2271 due to missing teams.\n",
      "Skipping game game_2022_2378 due to missing teams.\n",
      "Skipping game game_2022_2459 due to missing teams.\n",
      "Skipping game game_2022_2894 due to missing teams.\n",
      "Skipping game game_2022_3452 due to missing teams.\n",
      "Skipping game game_2022_3574 due to missing teams.\n",
      "Skipping game game_2022_4544 due to missing teams.\n",
      "Skipping game game_2022_4871 due to missing teams.\n",
      "Skipping game game_2022_4993 due to missing teams.\n",
      "Skipping game game_2022_192 due to missing teams.\n",
      "Skipping game game_2022_233 due to missing teams.\n",
      "Skipping game game_2022_285 due to missing teams.\n",
      "Skipping game game_2022_1091 due to missing teams.\n",
      "Skipping game game_2022_194 due to missing teams.\n",
      "Skipping game game_2022_235 due to missing teams.\n",
      "Skipping game game_2022_236 due to missing teams.\n",
      "Skipping game game_2022_289 due to missing teams.\n",
      "Skipping game game_2022_481 due to missing teams.\n",
      "Skipping game game_2022_541 due to missing teams.\n",
      "Skipping game game_2022_579 due to missing teams.\n",
      "Skipping game game_2022_781 due to missing teams.\n",
      "Skipping game game_2022_878 due to missing teams.\n",
      "Skipping game game_2022_879 due to missing teams.\n",
      "Skipping game game_2022_1492 due to missing teams.\n",
      "Skipping game game_2022_1513 due to missing teams.\n",
      "Skipping game game_2022_1597 due to missing teams.\n",
      "Skipping game game_2022_4673 due to missing teams.\n",
      "Skipping game game_2022_196 due to missing teams.\n",
      "Skipping game game_2022_397 due to missing teams.\n",
      "Skipping game game_2022_544 due to missing teams.\n",
      "Skipping game game_2022_629 due to missing teams.\n",
      "Skipping game game_2022_740 due to missing teams.\n",
      "Skipping game game_2022_824 due to missing teams.\n",
      "Skipping game game_2022_948 due to missing teams.\n",
      "Skipping game game_2022_1046 due to missing teams.\n",
      "Skipping game game_2022_1208 due to missing teams.\n",
      "Skipping game game_2022_1417 due to missing teams.\n",
      "Skipping game game_2022_1540 due to missing teams.\n",
      "Skipping game game_2022_1683 due to missing teams.\n",
      "Skipping game game_2022_1872 due to missing teams.\n",
      "Skipping game game_2022_1919 due to missing teams.\n",
      "Skipping game game_2022_2564 due to missing teams.\n",
      "Skipping game game_2022_2565 due to missing teams.\n",
      "Skipping game game_2022_197 due to missing teams.\n",
      "Skipping game game_2022_402 due to missing teams.\n",
      "Skipping game game_2022_850 due to missing teams.\n",
      "Skipping game game_2022_954 due to missing teams.\n",
      "Skipping game game_2022_1097 due to missing teams.\n",
      "Skipping game game_2022_1399 due to missing teams.\n",
      "Skipping game game_2022_1451 due to missing teams.\n",
      "Skipping game game_2022_1515 due to missing teams.\n",
      "Skipping game game_2022_1685 due to missing teams.\n",
      "Skipping game game_2022_1873 due to missing teams.\n",
      "Skipping game game_2022_1874 due to missing teams.\n",
      "Skipping game game_2022_1876 due to missing teams.\n",
      "Skipping game game_2022_1959 due to missing teams.\n",
      "Skipping game game_2022_1963 due to missing teams.\n",
      "Skipping game game_2022_2470 due to missing teams.\n",
      "Skipping game game_2022_2568 due to missing teams.\n",
      "Skipping game game_2022_3257 due to missing teams.\n",
      "Skipping game game_2022_3469 due to missing teams.\n",
      "Skipping game game_2022_3591 due to missing teams.\n",
      "Skipping game game_2022_4197 due to missing teams.\n",
      "Skipping game game_2022_4315 due to missing teams.\n",
      "Skipping game game_2022_295 due to missing teams.\n",
      "Skipping game game_2022_296 due to missing teams.\n",
      "Skipping game game_2022_297 due to missing teams.\n",
      "Skipping game game_2022_436 due to missing teams.\n",
      "Skipping game game_2022_634 due to missing teams.\n",
      "Skipping game game_2022_636 due to missing teams.\n",
      "Skipping game game_2022_786 due to missing teams.\n",
      "Skipping game game_2022_825 due to missing teams.\n",
      "Skipping game game_2022_883 due to missing teams.\n",
      "Skipping game game_2022_958 due to missing teams.\n",
      "Skipping game game_2022_1286 due to missing teams.\n",
      "Skipping game game_2022_1452 due to missing teams.\n",
      "Skipping game game_2022_1517 due to missing teams.\n",
      "Skipping game game_2022_1548 due to missing teams.\n",
      "Skipping game game_2022_1687 due to missing teams.\n",
      "Skipping game game_2022_2037 due to missing teams.\n",
      "Skipping game game_2022_2038 due to missing teams.\n",
      "Skipping game game_2022_2096 due to missing teams.\n",
      "Skipping game game_2022_2361 due to missing teams.\n",
      "Skipping game game_2022_2362 due to missing teams.\n",
      "Skipping game game_2022_2280 due to missing teams.\n",
      "Skipping game game_2022_2282 due to missing teams.\n",
      "Skipping game game_2022_2473 due to missing teams.\n",
      "Skipping game game_2022_2477 due to missing teams.\n",
      "Skipping game game_2022_2575 due to missing teams.\n",
      "Skipping game game_2022_2577 due to missing teams.\n",
      "Skipping game game_2022_2801 due to missing teams.\n",
      "Skipping game game_2022_2917 due to missing teams.\n",
      "Skipping game game_2022_3152 due to missing teams.\n",
      "Skipping game game_2022_3262 due to missing teams.\n",
      "Skipping game game_2022_3263 due to missing teams.\n",
      "Skipping game game_2022_3474 due to missing teams.\n",
      "Skipping game game_2022_3475 due to missing teams.\n",
      "Skipping game game_2022_3596 due to missing teams.\n",
      "Skipping game game_2022_3598 due to missing teams.\n",
      "Skipping game game_2022_4202 due to missing teams.\n",
      "Skipping game game_2022_4319 due to missing teams.\n",
      "Skipping game game_2022_4323 due to missing teams.\n",
      "Skipping game game_2022_4561 due to missing teams.\n",
      "Skipping game game_2022_4688 due to missing teams.\n",
      "Skipping game game_2022_4819 due to missing teams.\n",
      "Skipping game game_2022_4821 due to missing teams.\n",
      "Skipping game game_2022_5002 due to missing teams.\n",
      "Skipping game game_2022_5006 due to missing teams.\n",
      "Skipping game game_2022_5007 due to missing teams.\n",
      "Skipping game game_2022_240 due to missing teams.\n",
      "Skipping game game_2022_583 due to missing teams.\n",
      "Skipping game game_2022_742 due to missing teams.\n",
      "Skipping game game_2022_200 due to missing teams.\n",
      "Skipping game game_2022_344 due to missing teams.\n",
      "Skipping game game_2022_1770 due to missing teams.\n",
      "Skipping game game_2022_202 due to missing teams.\n",
      "Skipping game game_2022_346 due to missing teams.\n",
      "Skipping game game_2022_584 due to missing teams.\n",
      "Skipping game game_2022_1772 due to missing teams.\n",
      "Skipping game game_2022_1773 due to missing teams.\n",
      "Skipping game game_2022_298 due to missing teams.\n",
      "Skipping game game_2022_349 due to missing teams.\n",
      "Skipping game game_2022_551 due to missing teams.\n",
      "Skipping game game_2022_638 due to missing teams.\n",
      "Skipping game game_2022_828 due to missing teams.\n",
      "Skipping game game_2022_1495 due to missing teams.\n",
      "Skipping game game_2022_1550 due to missing teams.\n",
      "Skipping game game_2022_1775 due to missing teams.\n",
      "Skipping game game_2022_1881 due to missing teams.\n",
      "Skipping game game_2022_1927 due to missing teams.\n",
      "Skipping game game_2022_1928 due to missing teams.\n",
      "Skipping game game_2022_2041 due to missing teams.\n",
      "Skipping game game_2022_3875 due to missing teams.\n",
      "Skipping game game_2022_1690 due to missing teams.\n",
      "Skipping game game_2022_2133 due to missing teams.\n",
      "Skipping game game_2022_2135 due to missing teams.\n",
      "Skipping game game_2022_2223 due to missing teams.\n",
      "Skipping game game_2022_2288 due to missing teams.\n",
      "Skipping game game_2022_3159 due to missing teams.\n",
      "Skipping game game_2022_3481 due to missing teams.\n",
      "Skipping game game_2022_3611 due to missing teams.\n",
      "Skipping game game_2022_4569 due to missing teams.\n",
      "Skipping game game_2022_4699 due to missing teams.\n",
      "Skipping game game_2022_163 due to missing teams.\n",
      "Skipping game game_2022_586 due to missing teams.\n",
      "Skipping game game_2022_2662 due to missing teams.\n",
      "Skipping game game_2022_1609 due to missing teams.\n",
      "Skipping game game_2022_1741 due to missing teams.\n",
      "Skipping game game_2022_353 due to missing teams.\n",
      "Skipping game game_2022_495 due to missing teams.\n",
      "Skipping game game_2022_644 due to missing teams.\n",
      "Skipping game game_2022_1357 due to missing teams.\n",
      "Skipping game game_2022_204 due to missing teams.\n",
      "Skipping game game_2022_1612 due to missing teams.\n",
      "Skipping game game_2022_302 due to missing teams.\n",
      "Skipping game game_2022_898 due to missing teams.\n",
      "Skipping game game_2022_1778 due to missing teams.\n",
      "Skipping game game_2022_588 due to missing teams.\n",
      "Skipping game game_2022_902 due to missing teams.\n",
      "Skipping game game_2022_1615 due to missing teams.\n",
      "Skipping game game_2022_1294 due to missing teams.\n",
      "Skipping game game_2022_248 due to missing teams.\n",
      "Skipping game game_2022_304 due to missing teams.\n",
      "Skipping game game_2022_249 due to missing teams.\n",
      "Skipping game game_2022_205 due to missing teams.\n",
      "Skipping game game_2022_305 due to missing teams.\n",
      "Skipping game game_2022_441 due to missing teams.\n",
      "Skipping game game_2022_904 due to missing teams.\n",
      "Skipping game game_2022_1296 due to missing teams.\n",
      "Skipping game game_2022_1521 due to missing teams.\n",
      "Skipping game game_2022_1783 due to missing teams.\n",
      "Skipping game game_2022_250 due to missing teams.\n",
      "Skipping game game_2022_651 due to missing teams.\n",
      "Skipping game game_2022_358 due to missing teams.\n",
      "Skipping game game_2022_1461 due to missing teams.\n",
      "Skipping game game_2022_206 due to missing teams.\n",
      "Skipping game game_2022_1620 due to missing teams.\n",
      "Skipping game game_2022_499 due to missing teams.\n",
      "Skipping game game_2022_1888 due to missing teams.\n",
      "Skipping game game_2022_1621 due to missing teams.\n",
      "Skipping game game_2022_251 due to missing teams.\n",
      "Skipping game game_2022_252 due to missing teams.\n",
      "Skipping game game_2022_442 due to missing teams.\n",
      "Skipping game game_2022_720 due to missing teams.\n",
      "Skipping game game_2022_361 due to missing teams.\n",
      "Skipping game game_2022_1936 due to missing teams.\n",
      "Skipping game game_2022_1969 due to missing teams.\n",
      "Skipping game game_2022_655 due to missing teams.\n",
      "Skipping game game_2022_1695 due to missing teams.\n",
      "Skipping game game_2022_503 due to missing teams.\n",
      "Skipping game game_2022_1745 due to missing teams.\n",
      "Skipping game game_2022_1836 due to missing teams.\n",
      "Skipping game game_2022_253 due to missing teams.\n",
      "Skipping game game_2022_909 due to missing teams.\n",
      "Skipping game game_2022_1558 due to missing teams.\n",
      "Skipping game game_2022_1118 due to missing teams.\n",
      "Skipping game game_2022_362 due to missing teams.\n",
      "Skipping game game_2022_363 due to missing teams.\n",
      "Skipping game game_2022_991 due to missing teams.\n",
      "Skipping game game_2022_992 due to missing teams.\n",
      "Skipping game game_2022_1174 due to missing teams.\n",
      "Skipping game game_2022_445 due to missing teams.\n",
      "Skipping game game_2022_993 due to missing teams.\n",
      "Skipping game game_2022_255 due to missing teams.\n",
      "Skipping game game_2022_367 due to missing teams.\n",
      "Skipping game game_2022_661 due to missing teams.\n",
      "Skipping game game_2022_802 due to missing teams.\n",
      "Skipping game game_2022_1840 due to missing teams.\n",
      "Skipping game game_2022_1176 due to missing teams.\n",
      "Skipping game game_2022_1841 due to missing teams.\n",
      "Skipping game game_2022_368 due to missing teams.\n",
      "Skipping game game_2022_1246 due to missing teams.\n",
      "Skipping game game_2022_369 due to missing teams.\n",
      "Skipping game game_2022_750 due to missing teams.\n",
      "Skipping game game_2022_370 due to missing teams.\n",
      "Skipping game game_2022_592 due to missing teams.\n",
      "Skipping game game_2022_803 due to missing teams.\n",
      "Skipping game game_2022_257 due to missing teams.\n",
      "Skipping game game_2022_209 due to missing teams.\n",
      "Skipping game game_2022_1651 due to missing teams.\n",
      "Skipping game game_2022_914 due to missing teams.\n",
      "Skipping game game_2022_1627 due to missing teams.\n",
      "Skipping game game_2022_1843 due to missing teams.\n",
      "Skipping game game_2022_594 due to missing teams.\n",
      "Skipping game game_2022_567 due to missing teams.\n",
      "Skipping game game_2022_725 due to missing teams.\n",
      "Skipping game game_2022_835 due to missing teams.\n",
      "Skipping game game_2022_2297 due to missing teams.\n",
      "Skipping game game_2022_1722 due to missing teams.\n",
      "Skipping game game_2022_663 due to missing teams.\n",
      "Skipping game game_2022_2363 due to missing teams.\n",
      "Skipping game game_2022_2049 due to missing teams.\n",
      "Skipping game game_2022_412 due to missing teams.\n",
      "Skipping game game_2022_1502 due to missing teams.\n",
      "Skipping game game_2022_1705 due to missing teams.\n",
      "Skipping game game_2022_2182 due to missing teams.\n",
      "Skipping game game_2022_2365 due to missing teams.\n",
      "Skipping game game_2022_2604 due to missing teams.\n",
      "Skipping game game_2022_3296 due to missing teams.\n",
      "Skipping game game_2022_3629 due to missing teams.\n",
      "Skipping game game_2022_3696 due to missing teams.\n",
      "Skipping game game_2022_4722 due to missing teams.\n",
      "Skipping game game_2022_669 due to missing teams.\n",
      "Skipping game game_2022_1103 due to missing teams.\n",
      "Skipping game game_2022_1665 due to missing teams.\n",
      "Skipping game game_2022_1848 due to missing teams.\n",
      "Skipping game game_2022_2150 due to missing teams.\n",
      "Skipping game game_2022_450 due to missing teams.\n",
      "Skipping game game_2022_212 due to missing teams.\n",
      "Skipping game game_2022_1003 due to missing teams.\n",
      "Skipping game game_2022_1308 due to missing teams.\n",
      "Skipping game game_2022_377 due to missing teams.\n",
      "Skipping game game_2022_570 due to missing teams.\n",
      "Skipping game game_2022_2052 due to missing teams.\n",
      "Skipping game game_2022_518 due to missing teams.\n",
      "Skipping game game_2022_456 due to missing teams.\n",
      "Skipping game game_2022_383 due to missing teams.\n",
      "Skipping game game_2022_266 due to missing teams.\n",
      "Skipping game game_2022_598 due to missing teams.\n",
      "Skipping game game_2022_1655 due to missing teams.\n",
      "Skipping game game_2022_1796 due to missing teams.\n",
      "Skipping game game_2022_673 due to missing teams.\n",
      "Skipping game game_2022_924 due to missing teams.\n",
      "Skipping game game_2022_1008 due to missing teams.\n",
      "Skipping game game_2022_1898 due to missing teams.\n",
      "Skipping game game_2022_1634 due to missing teams.\n",
      "Skipping game game_2022_1079 due to missing teams.\n",
      "Skipping game game_2022_1105 due to missing teams.\n",
      "Skipping game game_2022_314 due to missing teams.\n",
      "Skipping game game_2022_523 due to missing teams.\n",
      "Skipping game game_2022_809 due to missing teams.\n",
      "Skipping game game_2022_1391 due to missing teams.\n",
      "Skipping game game_2022_4408 due to missing teams.\n",
      "Skipping game game_2022_419 due to missing teams.\n",
      "Skipping game game_2022_2648 due to missing teams.\n",
      "Skipping game game_2022_3191 due to missing teams.\n",
      "Skipping game game_2022_3519 due to missing teams.\n",
      "Skipping game game_2022_3684 due to missing teams.\n",
      "Skipping game game_2022_4244 due to missing teams.\n",
      "Skipping game game_2022_4585 due to missing teams.\n",
      "Skipping game game_2022_4732 due to missing teams.\n",
      "Skipping game game_2022_4892 due to missing teams.\n",
      "Skipping game game_2022_1901 due to missing teams.\n",
      "Skipping game game_2022_268 due to missing teams.\n",
      "Skipping game game_2022_1316 due to missing teams.\n",
      "Skipping game game_2022_1480 due to missing teams.\n",
      "Skipping game game_2022_1807 due to missing teams.\n",
      "Skipping game game_2022_1857 due to missing teams.\n",
      "Skipping game game_2022_1860 due to missing teams.\n",
      "Skipping game game_2022_2055 due to missing teams.\n",
      "Skipping game game_2022_4135 due to missing teams.\n",
      "Skipping game game_2022_2073 due to missing teams.\n",
      "Skipping game game_2022_2058 due to missing teams.\n",
      "Skipping game game_2022_2144 due to missing teams.\n",
      "Skipping game game_2022_2673 due to missing teams.\n",
      "Skipping game game_2022_2188 due to missing teams.\n",
      "Skipping game game_2022_4939 due to missing teams.\n",
      "Skipping game game_2022_4941 due to missing teams.\n",
      "Skipping game game_2022_5050 due to missing teams.\n",
      "Skipping game game_2022_4950 due to missing teams.\n",
      "Skipping game game_2022_5032 due to missing teams.\n",
      "Skipping game game_2022_5056 due to missing teams.\n",
      "Skipping game game_2022_4852 due to missing teams.\n",
      "Skipping game game_2022_2696 due to missing teams.\n",
      "Skipping game game_2022_5155 due to missing teams.\n",
      "Skipping game game_2022_2508 due to missing teams.\n",
      "Skipping game game_2022_3000 due to missing teams.\n",
      "Skipping game game_2022_3415 due to missing teams.\n",
      "Skipping game game_2022_3792 due to missing teams.\n",
      "Skipping game game_2022_3795 due to missing teams.\n",
      "Skipping game game_2022_4441 due to missing teams.\n"
     ]
    }
   ],
   "source": [
    "df_cls_diff = preprocess_data_diff(df_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ae33867",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:49:18.896880Z",
     "iopub.status.busy": "2025-02-18T17:49:18.896572Z",
     "iopub.status.idle": "2025-02-18T17:49:18.905153Z",
     "shell.execute_reply": "2025-02-18T17:49:18.904353Z"
    },
    "papermill": {
     "duration": 0.019093,
     "end_time": "2025-02-18T17:49:18.906758",
     "exception": false,
     "start_time": "2025-02-18T17:49:18.887665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_cls_diff = df_cls_diff.drop(columns = ['teamA', 'teamB', 'teamA_score', 'teamB_score'])\n",
    "\n",
    "A_HWN = df_cls_diff['A_H/W/N']\n",
    "B_HWN = df_cls_diff['B_H/W/N']\n",
    "df_cls_diff = df_cls_diff.drop(columns = ['A_H/W/N', 'B_H/W/N'])\n",
    "df_cls_diff['A_H/W/N'] = A_HWN\n",
    "df_cls_diff['B_H/W/N'] = B_HWN\n",
    "\n",
    "travel_dist = df_cls_diff['travel_dist% (A/B)']\n",
    "df_cls_diff = df_cls_diff.drop(columns = ['travel_dist% (A/B)'])\n",
    "df_cls_diff['travel_dist% (A/B)'] = travel_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5473b1ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:49:18.925054Z",
     "iopub.status.busy": "2025-02-18T17:49:18.924801Z",
     "iopub.status.idle": "2025-02-18T17:49:18.947543Z",
     "shell.execute_reply": "2025-02-18T17:49:18.946696Z"
    },
    "papermill": {
     "duration": 0.033106,
     "end_time": "2025-02-18T17:49:18.949043",
     "exception": false,
     "start_time": "2025-02-18T17:49:18.915937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W/L/D (teamA)</th>\n",
       "      <th>FGA_2% (A/B)</th>\n",
       "      <th>FGM_2% (A/B)</th>\n",
       "      <th>FGA_3% (A/B)</th>\n",
       "      <th>FGM_3% (A/B)</th>\n",
       "      <th>FTA% (A/B)</th>\n",
       "      <th>FTM% (A/B)</th>\n",
       "      <th>AST% (A/B)</th>\n",
       "      <th>BLK% (A/B)</th>\n",
       "      <th>STL% (A/B)</th>\n",
       "      <th>...</th>\n",
       "      <th>TOV_team% (A/B)</th>\n",
       "      <th>DREB% (A/B)</th>\n",
       "      <th>OREB% (A/B)</th>\n",
       "      <th>F_tech% (A/B)</th>\n",
       "      <th>F_personal% (A/B)</th>\n",
       "      <th>rest_days% (A/B)</th>\n",
       "      <th>prev_game_dist% (A/B)</th>\n",
       "      <th>A_H/W/N</th>\n",
       "      <th>B_H/W/N</th>\n",
       "      <th>travel_dist% (A/B)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.000000e-09</td>\n",
       "      <td>-0.010810</td>\n",
       "      <td>2.000000e-09</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>-0.037482</td>\n",
       "      <td>-0.024995</td>\n",
       "      <td>-0.005555</td>\n",
       "      <td>0.055498</td>\n",
       "      <td>-5.918999e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066568</td>\n",
       "      <td>2.000000e-09</td>\n",
       "      <td>2.000000e-09</td>\n",
       "      <td>2.000000e-09</td>\n",
       "      <td>0.070849</td>\n",
       "      <td>0.031568</td>\n",
       "      <td>-0.021141</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.024216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-3.869035e-02</td>\n",
       "      <td>-0.027020</td>\n",
       "      <td>-2.352507e-02</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.029158</td>\n",
       "      <td>0.039979</td>\n",
       "      <td>-0.027771</td>\n",
       "      <td>-0.077621</td>\n",
       "      <td>7.407274e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033321</td>\n",
       "      <td>2.050995e-02</td>\n",
       "      <td>-8.727737e-02</td>\n",
       "      <td>2.000000e-09</td>\n",
       "      <td>-0.025801</td>\n",
       "      <td>-0.005263</td>\n",
       "      <td>-0.020090</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.033908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-3.225793e-03</td>\n",
       "      <td>0.043216</td>\n",
       "      <td>-5.484686e-02</td>\n",
       "      <td>-0.009091</td>\n",
       "      <td>0.029158</td>\n",
       "      <td>0.024995</td>\n",
       "      <td>0.044415</td>\n",
       "      <td>0.033321</td>\n",
       "      <td>2.000000e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033321</td>\n",
       "      <td>5.635050e-02</td>\n",
       "      <td>-3.748243e-02</td>\n",
       "      <td>2.000000e-09</td>\n",
       "      <td>-0.019352</td>\n",
       "      <td>-0.073551</td>\n",
       "      <td>-0.011265</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.612764e-02</td>\n",
       "      <td>0.005405</td>\n",
       "      <td>-1.176416e-02</td>\n",
       "      <td>-0.009091</td>\n",
       "      <td>-0.037482</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>-0.011111</td>\n",
       "      <td>-0.011111</td>\n",
       "      <td>-7.407270e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033321</td>\n",
       "      <td>-1.025605e-02</td>\n",
       "      <td>-6.249917e-03</td>\n",
       "      <td>-3.997868e-02</td>\n",
       "      <td>-0.006452</td>\n",
       "      <td>0.052583</td>\n",
       "      <td>-0.006210</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3.224688e-02</td>\n",
       "      <td>0.037820</td>\n",
       "      <td>-1.286941e-01</td>\n",
       "      <td>-0.063551</td>\n",
       "      <td>0.103792</td>\n",
       "      <td>0.069886</td>\n",
       "      <td>0.038869</td>\n",
       "      <td>-0.022219</td>\n",
       "      <td>-5.180543e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033321</td>\n",
       "      <td>8.186764e-02</td>\n",
       "      <td>-1.249935e-02</td>\n",
       "      <td>2.000000e-09</td>\n",
       "      <td>-0.051567</td>\n",
       "      <td>-0.047333</td>\n",
       "      <td>0.023604</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   W/L/D (teamA)  FGA_2% (A/B)  FGM_2% (A/B)  FGA_3% (A/B)  FGM_3% (A/B)  \\\n",
       "0              0  2.000000e-09     -0.010810  2.000000e-09      0.009091   \n",
       "1              1 -3.869035e-02     -0.027020 -2.352507e-02      0.009091   \n",
       "2              1 -3.225793e-03      0.043216 -5.484686e-02     -0.009091   \n",
       "3              0  1.612764e-02      0.005405 -1.176416e-02     -0.009091   \n",
       "4              1  3.224688e-02      0.037820 -1.286941e-01     -0.063551   \n",
       "\n",
       "   FTA% (A/B)  FTM% (A/B)  AST% (A/B)  BLK% (A/B)    STL% (A/B)  ...  \\\n",
       "0   -0.037482   -0.024995   -0.005555    0.055498 -5.918999e-02  ...   \n",
       "1    0.029158    0.039979   -0.027771   -0.077621  7.407274e-03  ...   \n",
       "2    0.029158    0.024995    0.044415    0.033321  2.000000e-09  ...   \n",
       "3   -0.037482   -0.010000   -0.011111   -0.011111 -7.407270e-03  ...   \n",
       "4    0.103792    0.069886    0.038869   -0.022219 -5.180543e-02  ...   \n",
       "\n",
       "   TOV_team% (A/B)   DREB% (A/B)   OREB% (A/B)  F_tech% (A/B)  \\\n",
       "0        -0.066568  2.000000e-09  2.000000e-09   2.000000e-09   \n",
       "1         0.033321  2.050995e-02 -8.727737e-02   2.000000e-09   \n",
       "2         0.033321  5.635050e-02 -3.748243e-02   2.000000e-09   \n",
       "3        -0.033321 -1.025605e-02 -6.249917e-03  -3.997868e-02   \n",
       "4        -0.033321  8.186764e-02 -1.249935e-02   2.000000e-09   \n",
       "\n",
       "   F_personal% (A/B)  rest_days% (A/B)  prev_game_dist% (A/B)  A_H/W/N  \\\n",
       "0           0.070849          0.031568              -0.021141        1   \n",
       "1          -0.025801         -0.005263              -0.020090        1   \n",
       "2          -0.019352         -0.073551              -0.011265        1   \n",
       "3          -0.006452          0.052583              -0.006210        0   \n",
       "4          -0.051567         -0.047333               0.023604        0   \n",
       "\n",
       "   B_H/W/N  travel_dist% (A/B)  \n",
       "0        0           -0.024216  \n",
       "1        0           -0.033908  \n",
       "2        0           -0.012903  \n",
       "3        1            0.005791  \n",
       "4        1            0.027036  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cls_diff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45c74f04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:49:18.966624Z",
     "iopub.status.busy": "2025-02-18T17:49:18.966399Z",
     "iopub.status.idle": "2025-02-18T17:49:18.972149Z",
     "shell.execute_reply": "2025-02-18T17:49:18.971461Z"
    },
    "papermill": {
     "duration": 0.015857,
     "end_time": "2025-02-18T17:49:18.973404",
     "exception": false,
     "start_time": "2025-02-18T17:49:18.957547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_col = 'FGA_2% (A/B)'\n",
    "end_col_test = 'F_personal% (A/B)'\n",
    "df_test = df_cls_diff.loc[:,start_col : end_col_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "937e45be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:49:18.991203Z",
     "iopub.status.busy": "2025-02-18T17:49:18.991006Z",
     "iopub.status.idle": "2025-02-18T17:49:18.995009Z",
     "shell.execute_reply": "2025-02-18T17:49:18.994234Z"
    },
    "papermill": {
     "duration": 0.0143,
     "end_time": "2025-02-18T17:49:18.996481",
     "exception": false,
     "start_time": "2025-02-18T17:49:18.982181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our Regression Model Output 15 Labels.\n",
    "len(df_test.columns) # => Should be 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54045e0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:49:19.015432Z",
     "iopub.status.busy": "2025-02-18T17:49:19.015170Z",
     "iopub.status.idle": "2025-02-18T17:49:19.059831Z",
     "shell.execute_reply": "2025-02-18T17:49:19.058691Z"
    },
    "papermill": {
     "duration": 0.055612,
     "end_time": "2025-02-18T17:49:19.061214",
     "exception": false,
     "start_time": "2025-02-18T17:49:19.005602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4350, 20]) torch.float32\n",
      "torch.Size([4350]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "X = df_cls_diff.loc[:, start_col : 'travel_dist% (A/B)'].values\n",
    "\n",
    "y = df_cls_diff.loc[:, 'W/L/D (teamA)'].values\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.long)  \n",
    "\n",
    "\n",
    "print(X.shape, X.dtype)  # Check shape and type\n",
    "print(y.shape, y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "616dd11d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:49:19.081929Z",
     "iopub.status.busy": "2025-02-18T17:49:19.081689Z",
     "iopub.status.idle": "2025-02-18T17:49:19.159456Z",
     "shell.execute_reply": "2025-02-18T17:49:19.158349Z"
    },
    "papermill": {
     "duration": 0.088562,
     "end_time": "2025-02-18T17:49:19.160829",
     "exception": false,
     "start_time": "2025-02-18T17:49:19.072267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.0000e-09, -1.0810e-02,  2.0000e-09,  9.0907e-03, -3.7482e-02,\n",
      "        -2.4995e-02, -5.5555e-03,  5.5498e-02, -5.9190e-02,  1.9510e-02,\n",
      "        -6.6568e-02,  2.0000e-09,  2.0000e-09,  2.0000e-09,  7.0849e-02,\n",
      "         3.1568e-02, -2.1141e-02,  1.0000e+00,  0.0000e+00, -2.4216e-02])\n",
      "-----------------------------------------------------------\n",
      "tensor(1.)\n",
      "tensor(0.)\n",
      "Number of Features: 20\n",
      "Label: tensor([0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(X[0])\n",
    "\n",
    "print(\"-\"*59)\n",
    "\n",
    "print(X[0][17])\n",
    "print(X[0][18])\n",
    "\n",
    "print(f\"Number of Features: {len(X[0])}\")\n",
    "A_HWN_idx = 17\n",
    "B_HWN_idx = 18\n",
    "\n",
    "print(f\"Label: {y[:3]}\")\n",
    "\n",
    "# [15 Features] -> F_Personal + Rest + Prev game dist + HAN_A + HAN_B + travel dist\n",
    "# Total = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04183ac2",
   "metadata": {
    "papermill": {
     "duration": 0.008361,
     "end_time": "2025-02-18T17:49:19.178467",
     "exception": false,
     "start_time": "2025-02-18T17:49:19.170106",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "------------------------\n",
    "# **Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc98cbee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:49:19.196970Z",
     "iopub.status.busy": "2025-02-18T17:49:19.196719Z",
     "iopub.status.idle": "2025-02-18T17:49:19.282350Z",
     "shell.execute_reply": "2025-02-18T17:49:19.281596Z"
    },
    "papermill": {
     "duration": 0.096845,
     "end_time": "2025-02-18T17:49:19.283570",
     "exception": false,
     "start_time": "2025-02-18T17:49:19.186725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9c2dee0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:49:19.301236Z",
     "iopub.status.busy": "2025-02-18T17:49:19.300996Z",
     "iopub.status.idle": "2025-02-18T17:49:19.310188Z",
     "shell.execute_reply": "2025-02-18T17:49:19.309428Z"
    },
    "papermill": {
     "duration": 0.019196,
     "end_time": "2025-02-18T17:49:19.311406",
     "exception": false,
     "start_time": "2025-02-18T17:49:19.292210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3045, 20])\n",
      "torch.Size([3045])\n",
      "Type of X_train and X_test: <class 'torch.Tensor'> | <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# 7/3 Train/Val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(X_train.shape)  # Should be (num_samples, num_features) → (N, 19)\n",
    "print(y_train.shape)  # Should be (num_samples, num_outputs) → (N, 15)\n",
    "print(f\"Type of X_train and X_test: {type(X_train)} | {type(X_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da604c91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:49:19.329086Z",
     "iopub.status.busy": "2025-02-18T17:49:19.328854Z",
     "iopub.status.idle": "2025-02-18T17:49:19.333109Z",
     "shell.execute_reply": "2025-02-18T17:49:19.332498Z"
    },
    "papermill": {
     "duration": 0.014308,
     "end_time": "2025-02-18T17:49:19.334291",
     "exception": false,
     "start_time": "2025-02-18T17:49:19.319983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class bkb_dataset(Dataset):\n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature = self.data[idx]\n",
    "        label = self.label[idx]\n",
    "\n",
    "        return {\"input_ids\": feature, \"labels\": label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41e2e2e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:49:19.351531Z",
     "iopub.status.busy": "2025-02-18T17:49:19.351328Z",
     "iopub.status.idle": "2025-02-18T17:49:19.355938Z",
     "shell.execute_reply": "2025-02-18T17:49:19.355006Z"
    },
    "papermill": {
     "duration": 0.014607,
     "end_time": "2025-02-18T17:49:19.357186",
     "exception": false,
     "start_time": "2025-02-18T17:49:19.342579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train_set: 3045\n",
      "Length of val_set: 1305\n"
     ]
    }
   ],
   "source": [
    "train_set = bkb_dataset(\n",
    "    X_train,\n",
    "    y_train,\n",
    ")\n",
    "\n",
    "val_set = bkb_dataset(\n",
    "    X_val,\n",
    "    y_val,\n",
    ")\n",
    "\n",
    "print(f\"Length of train_set: {len(train_set)}\")\n",
    "print(f\"Length of val_set: {len(val_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d526683b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:49:19.374848Z",
     "iopub.status.busy": "2025-02-18T17:49:19.374611Z",
     "iopub.status.idle": "2025-02-18T17:49:19.379772Z",
     "shell.execute_reply": "2025-02-18T17:49:19.378855Z"
    },
    "papermill": {
     "duration": 0.015436,
     "end_time": "2025-02-18T17:49:19.381004",
     "exception": false,
     "start_time": "2025-02-18T17:49:19.365568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length train_loader: 12\n",
      "Length val_loader: 41\n"
     ]
    }
   ],
   "source": [
    "train_batch = 256\n",
    "test_batch = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size = train_batch,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_size = test_batch,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "print(f\"Length train_loader: {len(train_loader)}\")\n",
    "print(f\"Length val_loader: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0850795d",
   "metadata": {
    "papermill": {
     "duration": 0.008298,
     "end_time": "2025-02-18T17:49:19.397587",
     "exception": false,
     "start_time": "2025-02-18T17:49:19.389289",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "-------------------\n",
    "# **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae0c5172",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:49:19.415601Z",
     "iopub.status.busy": "2025-02-18T17:49:19.415352Z",
     "iopub.status.idle": "2025-02-18T17:49:19.774301Z",
     "shell.execute_reply": "2025-02-18T17:49:19.773266Z"
    },
    "papermill": {
     "duration": 0.36995,
     "end_time": "2025-02-18T17:49:19.776145",
     "exception": false,
     "start_time": "2025-02-18T17:49:19.406195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "HUGGINGFACE_TOKEN = user_secrets.get_secret(\"HF_TOKEN\")\n",
    "\n",
    "# Login to Hugging Face\n",
    "login(HUGGINGFACE_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa21b686",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:49:19.795521Z",
     "iopub.status.busy": "2025-02-18T17:49:19.795241Z",
     "iopub.status.idle": "2025-02-18T17:49:21.318230Z",
     "shell.execute_reply": "2025-02-18T17:49:21.317064Z"
    },
    "papermill": {
     "duration": 1.534337,
     "end_time": "2025-02-18T17:49:21.319968",
     "exception": false,
     "start_time": "2025-02-18T17:49:19.785631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf9c072638f74ac1a339e75c78e5bd39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Shape: torch.Size([1, 2])\n",
      "Output: tensor([[0.0205, 0.0831]], grad_fn=<AddmmBackward0>)\n",
      "After Softmax: tensor([[0.4844, 0.5156]], grad_fn=<SoftmaxBackward0>)\n",
      "Loss: 0.7249125242233276 | True Label: tensor([0])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class FeatureGrouping_cls(nn.Module):\n",
    "    def __init__(self, num_features=20, max_groups=3, embed_dim=4, output_dim=2, resnet_model=\"resnet50\", finetune = True):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        self.max_groups = max_groups\n",
    "        self.embed_dim = embed_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        # Embedding for home_away (3 categories: Home, Away, Neutral)\n",
    "        self.home_away_embed = nn.Embedding(3, embed_dim)\n",
    "\n",
    "        # Adjust feature count after embedding replacement\n",
    "        self.adjusted_num_features = num_features - 2 + 2*embed_dim  # 20 - 2 + 2*4 = 26\n",
    "\n",
    "        # Calculate the maximum features per group to ensure consistent dimensions\n",
    "        self.max_features_per_group = self.adjusted_num_features\n",
    "\n",
    "        # Learnable logits for feature assignment\n",
    "        self.assignment_logits = nn.Parameter(torch.randn(self.adjusted_num_features, max_groups))\n",
    "\n",
    "        # Self-Attention layers for each possible number of groups\n",
    "        self.attention_layers = nn.ModuleDict({\n",
    "            f\"attn_{g}\": nn.MultiheadAttention(\n",
    "                embed_dim=self.max_features_per_group,\n",
    "                num_heads=1,\n",
    "                batch_first=True\n",
    "            )\n",
    "            for g in range(1, max_groups + 1)\n",
    "        })\n",
    "\n",
    "        # Reduce channels before ResNet\n",
    "        self.channel_reducer = nn.Conv2d(in_channels=max_groups, out_channels=3, kernel_size=1)\n",
    "\n",
    "        # Pretrained ResNet model\n",
    "        self.resnet = timm.create_model(resnet_model, pretrained=True)\n",
    "        in_features = self.resnet.get_classifier().in_features\n",
    "        self.resnet.reset_classifier(0)\n",
    "\n",
    "        # Final regression head\n",
    "        self.fc = nn.Linear(in_features, output_dim)\n",
    "        \n",
    "        if finetune:\n",
    "            for param in self.resnet.parameters():\n",
    "                param.requires_grad = True\n",
    "        else:\n",
    "            for param in self.resnet.parameters():\n",
    "                param.requires_grad = False\n",
    "                    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        # Extract home_away index and convert to embeddings\n",
    "        A_home_away_idx = x[:, 17].long().clamp(0, 2)\n",
    "        B_home_away_idx = x[:, 18].long().clamp(0, 2)\n",
    "        \n",
    "        A_home_away_embed = self.home_away_embed(A_home_away_idx)\n",
    "        B_home_away_embed = self.home_away_embed(B_home_away_idx)\n",
    "        \n",
    "        x = torch.cat([x[:, :17], A_home_away_embed, B_home_away_embed, x[:, 19:]], dim=1)\n",
    "\n",
    "        # Hard feature assignment\n",
    "        assignment_hard = torch.nn.functional.gumbel_softmax(self.assignment_logits, tau=0.5, hard=True, dim=1)\n",
    "\n",
    "        all_group_outputs = []\n",
    "\n",
    "        # Process different group configurations\n",
    "        for num_groups in range(1, self.max_groups + 1):\n",
    "            # Split features into groups\n",
    "            groups = []\n",
    "            features_per_group = self.adjusted_num_features // num_groups\n",
    "            \n",
    "            for g in range(num_groups):\n",
    "                start_idx = g * features_per_group\n",
    "                end_idx = min(start_idx + features_per_group, self.adjusted_num_features)\n",
    "                group_features = x[:, start_idx:end_idx]\n",
    "                \n",
    "                # Pad to match max_features_per_group\n",
    "                if group_features.shape[1] < self.max_features_per_group:\n",
    "                    pad_size = self.max_features_per_group - group_features.shape[1]\n",
    "                    padding = torch.zeros(batch_size, pad_size, device=x.device)\n",
    "                    group_features = torch.cat([group_features, padding], dim=1)\n",
    "                \n",
    "                groups.append(group_features)\n",
    "\n",
    "            # Process each group with attention\n",
    "            processed_groups = []\n",
    "            for g in range(num_groups):\n",
    "                group_features = groups[g].unsqueeze(1)\n",
    "                attn_output, _ = self.attention_layers[f\"attn_{num_groups}\"](\n",
    "                    group_features, group_features, group_features)\n",
    "                processed_groups.append(attn_output)\n",
    "\n",
    "            # Combine processed groups\n",
    "            group_output = torch.cat(processed_groups, dim=1)\n",
    "            \n",
    "            # Pad to match max_groups if necessary\n",
    "            if num_groups < self.max_groups:\n",
    "                padding = torch.zeros(\n",
    "                    batch_size,\n",
    "                    self.max_groups - num_groups,\n",
    "                    self.max_features_per_group,\n",
    "                    device=x.device\n",
    "                )\n",
    "                group_output = torch.cat([group_output, padding], dim=1)\n",
    "            \n",
    "            all_group_outputs.append(group_output)\n",
    "\n",
    "        # Stack all configurations\n",
    "        x_final = torch.stack(all_group_outputs, dim=1)  # [B, max_groups, max_groups, Features]\n",
    "        \n",
    "        # Reshape for channel reducer\n",
    "        x_final = x_final.mean(dim=1)  # [B, max_groups, Features]\n",
    "        x_final = x_final.permute(0, 2, 1)  # [B, Features, max_groups]\n",
    "        x_final = x_final.mean(dim=1).unsqueeze(-1).unsqueeze(-1)  # [B, max_groups, 1, 1]\n",
    "        \n",
    "        # Apply channel reduction\n",
    "        x_final = self.channel_reducer(x_final)  # [B, 3, 1, 1]\n",
    "        \n",
    "        # Prepare for ResNet\n",
    "        x_final = x_final.expand(-1, -1, 224, 224)  # [B, 3, 224, 224]\n",
    "\n",
    "        # Process through ResNet and final layer\n",
    "        x_final = self.resnet(x_final)\n",
    "        output = self.fc(x_final)\n",
    "\n",
    "        return output\n",
    "\n",
    "batch_size = 1\n",
    "x = torch.randn(batch_size, 20)\n",
    "\n",
    "# Ensure y[0] is properly wrapped in a tensor\n",
    "test_label = torch.tensor([y[0]], dtype=torch.long)  # Added batch dimension\n",
    "\n",
    "# Model\n",
    "model = FeatureGrouping_cls(resnet_model=\"resnet50\")\n",
    "output = model(x)\n",
    "\n",
    "print(f\"Output Shape: {output.shape}\")  # Expected: (1, 2)\n",
    "print(f\"Output: {output}\")\n",
    "\n",
    "# Softmax check\n",
    "sm = nn.Softmax(dim=-1)\n",
    "print(f\"After Softmax: {sm(output)}\")\n",
    "\n",
    "# Loss computation\n",
    "loss = nn.CrossEntropyLoss()\n",
    "pred = loss(output, test_label)\n",
    "print(f\"Loss: {pred} | True Label: {test_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9841e9d5",
   "metadata": {
    "papermill": {
     "duration": 0.008457,
     "end_time": "2025-02-18T17:49:21.337418",
     "exception": false,
     "start_time": "2025-02-18T17:49:21.328961",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "----------------------\n",
    "# **Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1135c61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:49:21.356008Z",
     "iopub.status.busy": "2025-02-18T17:49:21.355743Z",
     "iopub.status.idle": "2025-02-18T17:49:35.855914Z",
     "shell.execute_reply": "2025-02-18T17:49:35.854904Z"
    },
    "papermill": {
     "duration": 14.511548,
     "end_time": "2025-02-18T17:49:35.857901",
     "exception": false,
     "start_time": "2025-02-18T17:49:21.346353",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2132b5d6a3474a8d8c8fc60e8ae4e006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import PreTrainedModel, PretrainedConfig\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "class FeatureGroupingConfig(PretrainedConfig):\n",
    "    model_type = \"feature_grouping\"\n",
    "\n",
    "    def __init__(self, num_features=20, output_dim=2, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_features = num_features\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "class FeatureGroupingModel(PreTrainedModel):\n",
    "    config_class = FeatureGroupingConfig\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.model = FeatureGrouping_cls(  # Ensure this is defined somewhere\n",
    "            num_features=config.num_features, \n",
    "            output_dim=config.output_dim\n",
    "        )\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input_ids, labels=None):\n",
    "        logits = self.model(input_ids)  # Raw logits\n",
    "\n",
    "        loss = None\n",
    "        auc_roc = None\n",
    "        f1 = None\n",
    "\n",
    "        if labels is not None:\n",
    "            loss = self.loss_fn(logits, labels)  \n",
    "\n",
    "            # Convert logits to probabilities\n",
    "            probs = F.softmax(logits, dim=-1)[:, 1].detach().cpu().numpy()\n",
    "            labels_np = labels.detach().cpu().numpy()\n",
    "\n",
    "            # Compute AUC-ROC only if both classes exist\n",
    "            if len(set(labels_np)) > 1:\n",
    "                auc_roc = roc_auc_score(labels_np, probs)\n",
    "            else:\n",
    "                auc_roc = 0.0\n",
    "\n",
    "            # Compute F1-score\n",
    "            preds = torch.argmax(logits, dim=-1).detach().cpu().numpy()\n",
    "            f1 = f1_score(labels_np, preds, average=\"macro\")\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss, \n",
    "            logits=logits,\n",
    "            hidden_states=None, \n",
    "            attentions=None\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2343c2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:49:35.883948Z",
     "iopub.status.busy": "2025-02-18T17:49:35.883389Z",
     "iopub.status.idle": "2025-02-18T17:49:35.889068Z",
     "shell.execute_reply": "2025-02-18T17:49:35.888167Z"
    },
    "papermill": {
     "duration": 0.017092,
     "end_time": "2025-02-18T17:49:35.890579",
     "exception": false,
     "start_time": "2025-02-18T17:49:35.873487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "\n",
    "    # Convert logits to a PyTorch tensor\n",
    "    logits = torch.tensor(logits)  \n",
    "\n",
    "    # Apply softmax to get probabilities\n",
    "    probs = torch.nn.functional.softmax(logits, dim=1)[:, 1].cpu().numpy()  # Convert back to NumPy\n",
    "\n",
    "    # Ensure labels are in NumPy array format\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Convert probabilities to binary predictions\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "    # Compute metrics\n",
    "    auc_roc = roc_auc_score(labels, probs) if len(set(labels)) > 1 else 0.0  # Prevent single-class error\n",
    "    f1 = f1_score(labels, preds, average=\"macro\")\n",
    "\n",
    "    print(f\"DEBUG - AUC-ROC: {auc_roc}, F1: {f1}\")\n",
    "\n",
    "    return {\"auc_roc\": auc_roc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b779be4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:49:35.909582Z",
     "iopub.status.busy": "2025-02-18T17:49:35.909324Z",
     "iopub.status.idle": "2025-02-18T18:11:53.739847Z",
     "shell.execute_reply": "2025-02-18T18:11:53.738899Z"
    },
    "papermill": {
     "duration": 1337.841692,
     "end_time": "2025-02-18T18:11:53.741139",
     "exception": false,
     "start_time": "2025-02-18T17:49:35.899447",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1440' max='1440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1440/1440 22:06, Epoch 60/60]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Auc Roc</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.691900</td>\n",
       "      <td>0.694635</td>\n",
       "      <td>0.462440</td>\n",
       "      <td>0.333844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.685100</td>\n",
       "      <td>0.811843</td>\n",
       "      <td>0.626040</td>\n",
       "      <td>0.582124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.679200</td>\n",
       "      <td>0.696116</td>\n",
       "      <td>0.409136</td>\n",
       "      <td>0.423278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.676100</td>\n",
       "      <td>0.696563</td>\n",
       "      <td>0.400884</td>\n",
       "      <td>0.413702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.672000</td>\n",
       "      <td>0.682157</td>\n",
       "      <td>0.642059</td>\n",
       "      <td>0.541666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.664000</td>\n",
       "      <td>0.665998</td>\n",
       "      <td>0.648109</td>\n",
       "      <td>0.583517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.661700</td>\n",
       "      <td>0.666803</td>\n",
       "      <td>0.663489</td>\n",
       "      <td>0.604471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.655300</td>\n",
       "      <td>0.654623</td>\n",
       "      <td>0.676325</td>\n",
       "      <td>0.633622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.649500</td>\n",
       "      <td>0.644047</td>\n",
       "      <td>0.691695</td>\n",
       "      <td>0.633116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.642300</td>\n",
       "      <td>0.642393</td>\n",
       "      <td>0.688845</td>\n",
       "      <td>0.619100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.636000</td>\n",
       "      <td>0.632390</td>\n",
       "      <td>0.723533</td>\n",
       "      <td>0.656259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.627700</td>\n",
       "      <td>0.632885</td>\n",
       "      <td>0.725802</td>\n",
       "      <td>0.652844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.616000</td>\n",
       "      <td>0.614404</td>\n",
       "      <td>0.743916</td>\n",
       "      <td>0.680876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.611400</td>\n",
       "      <td>0.605944</td>\n",
       "      <td>0.743643</td>\n",
       "      <td>0.683881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.599200</td>\n",
       "      <td>0.609644</td>\n",
       "      <td>0.754163</td>\n",
       "      <td>0.673379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.589900</td>\n",
       "      <td>0.581158</td>\n",
       "      <td>0.791590</td>\n",
       "      <td>0.719447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.580100</td>\n",
       "      <td>0.578562</td>\n",
       "      <td>0.782741</td>\n",
       "      <td>0.698081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.570900</td>\n",
       "      <td>0.553569</td>\n",
       "      <td>0.830763</td>\n",
       "      <td>0.765516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.556100</td>\n",
       "      <td>0.541661</td>\n",
       "      <td>0.825390</td>\n",
       "      <td>0.750012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.547600</td>\n",
       "      <td>0.528842</td>\n",
       "      <td>0.845018</td>\n",
       "      <td>0.768674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.535500</td>\n",
       "      <td>0.516229</td>\n",
       "      <td>0.855805</td>\n",
       "      <td>0.771405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.518800</td>\n",
       "      <td>0.493134</td>\n",
       "      <td>0.881230</td>\n",
       "      <td>0.799105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.520900</td>\n",
       "      <td>0.527002</td>\n",
       "      <td>0.865523</td>\n",
       "      <td>0.763903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.509000</td>\n",
       "      <td>0.486494</td>\n",
       "      <td>0.873103</td>\n",
       "      <td>0.783821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.496900</td>\n",
       "      <td>0.471506</td>\n",
       "      <td>0.885868</td>\n",
       "      <td>0.791930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.489200</td>\n",
       "      <td>0.501413</td>\n",
       "      <td>0.864581</td>\n",
       "      <td>0.758366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.480700</td>\n",
       "      <td>0.456394</td>\n",
       "      <td>0.907007</td>\n",
       "      <td>0.843457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.464800</td>\n",
       "      <td>0.433382</td>\n",
       "      <td>0.907475</td>\n",
       "      <td>0.821025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.452900</td>\n",
       "      <td>0.422983</td>\n",
       "      <td>0.905983</td>\n",
       "      <td>0.829408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.444300</td>\n",
       "      <td>0.447290</td>\n",
       "      <td>0.917473</td>\n",
       "      <td>0.837734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.442100</td>\n",
       "      <td>0.413288</td>\n",
       "      <td>0.910777</td>\n",
       "      <td>0.841146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.429300</td>\n",
       "      <td>0.392385</td>\n",
       "      <td>0.930509</td>\n",
       "      <td>0.862055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.419800</td>\n",
       "      <td>0.410520</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.849480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.413700</td>\n",
       "      <td>0.400131</td>\n",
       "      <td>0.925652</td>\n",
       "      <td>0.853473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.411800</td>\n",
       "      <td>0.389669</td>\n",
       "      <td>0.934833</td>\n",
       "      <td>0.868081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.407000</td>\n",
       "      <td>0.383372</td>\n",
       "      <td>0.928640</td>\n",
       "      <td>0.836935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.395300</td>\n",
       "      <td>0.362457</td>\n",
       "      <td>0.937076</td>\n",
       "      <td>0.861933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.391800</td>\n",
       "      <td>0.351287</td>\n",
       "      <td>0.941405</td>\n",
       "      <td>0.858537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.379900</td>\n",
       "      <td>0.343865</td>\n",
       "      <td>0.939777</td>\n",
       "      <td>0.868042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.392800</td>\n",
       "      <td>0.347210</td>\n",
       "      <td>0.941419</td>\n",
       "      <td>0.863197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.375600</td>\n",
       "      <td>0.347131</td>\n",
       "      <td>0.937642</td>\n",
       "      <td>0.871811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.376800</td>\n",
       "      <td>0.336271</td>\n",
       "      <td>0.943876</td>\n",
       "      <td>0.873346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.372800</td>\n",
       "      <td>0.334725</td>\n",
       "      <td>0.947047</td>\n",
       "      <td>0.881125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.369900</td>\n",
       "      <td>0.329363</td>\n",
       "      <td>0.946697</td>\n",
       "      <td>0.866201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.364300</td>\n",
       "      <td>0.333767</td>\n",
       "      <td>0.947641</td>\n",
       "      <td>0.860698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.382100</td>\n",
       "      <td>0.336575</td>\n",
       "      <td>0.945227</td>\n",
       "      <td>0.860548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.365300</td>\n",
       "      <td>0.330572</td>\n",
       "      <td>0.947632</td>\n",
       "      <td>0.877952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.354300</td>\n",
       "      <td>0.318819</td>\n",
       "      <td>0.947686</td>\n",
       "      <td>0.879502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.364900</td>\n",
       "      <td>0.320532</td>\n",
       "      <td>0.947578</td>\n",
       "      <td>0.888112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.357500</td>\n",
       "      <td>0.315793</td>\n",
       "      <td>0.949445</td>\n",
       "      <td>0.891954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.355600</td>\n",
       "      <td>0.312826</td>\n",
       "      <td>0.950516</td>\n",
       "      <td>0.886526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.354700</td>\n",
       "      <td>0.319943</td>\n",
       "      <td>0.948637</td>\n",
       "      <td>0.878783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.364700</td>\n",
       "      <td>0.332198</td>\n",
       "      <td>0.946643</td>\n",
       "      <td>0.867611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.368200</td>\n",
       "      <td>0.315383</td>\n",
       "      <td>0.948797</td>\n",
       "      <td>0.877920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.364600</td>\n",
       "      <td>0.326291</td>\n",
       "      <td>0.949001</td>\n",
       "      <td>0.861334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.353100</td>\n",
       "      <td>0.317291</td>\n",
       "      <td>0.949313</td>\n",
       "      <td>0.884222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.355700</td>\n",
       "      <td>0.312462</td>\n",
       "      <td>0.950671</td>\n",
       "      <td>0.888857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.366300</td>\n",
       "      <td>0.319776</td>\n",
       "      <td>0.948430</td>\n",
       "      <td>0.889632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.354800</td>\n",
       "      <td>0.315882</td>\n",
       "      <td>0.949875</td>\n",
       "      <td>0.888774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.352300</td>\n",
       "      <td>0.320375</td>\n",
       "      <td>0.949107</td>\n",
       "      <td>0.873239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG - AUC-ROC: 0.4624395777843543, F1: 0.333843797856049\n",
      "DEBUG - AUC-ROC: 0.6260399197658741, F1: 0.5821236444368543\n",
      "DEBUG - AUC-ROC: 0.40913649666239194, F1: 0.4232781355705467\n",
      "DEBUG - AUC-ROC: 0.400884078599379, F1: 0.41370205765867885\n",
      "DEBUG - AUC-ROC: 0.6420585596377251, F1: 0.5416655737872718\n",
      "DEBUG - AUC-ROC: 0.6481090019119022, F1: 0.5835167580116667\n",
      "DEBUG - AUC-ROC: 0.6634887752082188, F1: 0.6044712128960952\n",
      "DEBUG - AUC-ROC: 0.6763248260732724, F1: 0.6336216010487589\n",
      "DEBUG - AUC-ROC: 0.6916952042728899, F1: 0.6331164930227768\n",
      "DEBUG - AUC-ROC: 0.688844966811821, F1: 0.6190998309224564\n",
      "DEBUG - AUC-ROC: 0.7235328382117373, F1: 0.6562591132726879\n",
      "DEBUG - AUC-ROC: 0.7258017540645537, F1: 0.6528442093135105\n",
      "DEBUG - AUC-ROC: 0.7439155005002889, F1: 0.6808760683760684\n",
      "DEBUG - AUC-ROC: 0.7436430426960169, F1: 0.6838811488132754\n",
      "DEBUG - AUC-ROC: 0.7541632022247589, F1: 0.6733792894477691\n",
      "DEBUG - AUC-ROC: 0.7915897443124433, F1: 0.719447440297359\n",
      "DEBUG - AUC-ROC: 0.7827407376090418, F1: 0.6980808238414729\n",
      "DEBUG - AUC-ROC: 0.8307625999990605, F1: 0.7655160021984526\n",
      "DEBUG - AUC-ROC: 0.8253897790743011, F1: 0.7500117522623104\n",
      "DEBUG - AUC-ROC: 0.8450184848527553, F1: 0.768673895779761\n",
      "DEBUG - AUC-ROC: 0.8558052302503324, F1: 0.7714048999881642\n",
      "DEBUG - AUC-ROC: 0.8812295363050026, F1: 0.7991052542516288\n",
      "DEBUG - AUC-ROC: 0.8655232833983943, F1: 0.7639032935853274\n",
      "DEBUG - AUC-ROC: 0.8731027776603391, F1: 0.7838207959554349\n",
      "DEBUG - AUC-ROC: 0.8858683653001498, F1: 0.7919300547847286\n",
      "DEBUG - AUC-ROC: 0.8645814249543162, F1: 0.7583658766496095\n",
      "DEBUG - AUC-ROC: 0.9070073328729736, F1: 0.8434574603204471\n",
      "DEBUG - AUC-ROC: 0.9074747389337504, F1: 0.8210254813473665\n",
      "DEBUG - AUC-ROC: 0.9059832673327791, F1: 0.8294081485564082\n",
      "DEBUG - AUC-ROC: 0.9174734705956961, F1: 0.8377344881171472\n",
      "DEBUG - AUC-ROC: 0.9107771154234605, F1: 0.8411461166404492\n",
      "DEBUG - AUC-ROC: 0.9305091672656042, F1: 0.8620552765471654\n",
      "DEBUG - AUC-ROC: 0.9285714285714286, F1: 0.8494795516281961\n",
      "DEBUG - AUC-ROC: 0.9256519022722042, F1: 0.853473275060858\n",
      "DEBUG - AUC-ROC: 0.934833260521334, F1: 0.8680814150304671\n",
      "DEBUG - AUC-ROC: 0.9286395430224965, F1: 0.8369353764157228\n",
      "DEBUG - AUC-ROC: 0.937076339858228, F1: 0.861932683807625\n",
      "DEBUG - AUC-ROC: 0.9414051306623072, F1: 0.8585365853658536\n",
      "DEBUG - AUC-ROC: 0.9397774301591999, F1: 0.8680423280423282\n",
      "DEBUG - AUC-ROC: 0.9414192233073558, F1: 0.8631965907805963\n",
      "DEBUG - AUC-ROC: 0.9376423944343448, F1: 0.8718111603432486\n",
      "DEBUG - AUC-ROC: 0.9438760410941529, F1: 0.8733463560277606\n",
      "DEBUG - AUC-ROC: 0.9470468862300766, F1: 0.8811252593911192\n",
      "DEBUG - AUC-ROC: 0.9466969188780375, F1: 0.8662008513366362\n",
      "DEBUG - AUC-ROC: 0.9476411260962904, F1: 0.8606977115866739\n",
      "DEBUG - AUC-ROC: 0.9452265862446388, F1: 0.860548031094415\n",
      "DEBUG - AUC-ROC: 0.9476317309995913, F1: 0.8779519430812965\n",
      "DEBUG - AUC-ROC: 0.9476857528056107, F1: 0.8795021645912743\n",
      "DEBUG - AUC-ROC: 0.9475777091935719, F1: 0.8881115020882564\n",
      "DEBUG - AUC-ROC: 0.9494449846625047, F1: 0.8919540229885057\n",
      "DEBUG - AUC-ROC: 0.9505160256861943, F1: 0.8865260060726271\n",
      "DEBUG - AUC-ROC: 0.9486370063463878, F1: 0.8787830687830688\n",
      "DEBUG - AUC-ROC: 0.946642897072018, F1: 0.8676108374384237\n",
      "DEBUG - AUC-ROC: 0.9487967229902713, F1: 0.8779197734136395\n",
      "DEBUG - AUC-ROC: 0.9490010663434754, F1: 0.8613341204250295\n",
      "DEBUG - AUC-ROC: 0.9493134533087182, F1: 0.8842215721377367\n",
      "DEBUG - AUC-ROC: 0.9506710447817284, F1: 0.8888573021148977\n",
      "DEBUG - AUC-ROC: 0.948430314219009, F1: 0.8896317770270588\n",
      "DEBUG - AUC-ROC: 0.9498748103364855, F1: 0.8887736802289595\n",
      "DEBUG - AUC-ROC: 0.9491067611813394, F1: 0.87323898887894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'loss': 0.6919, 'grad_norm': 7.8175740242004395, 'learning_rate': 9.993147673772869e-06, 'epoch': 1.0, 'step': 24}, {'eval_loss': 0.694635272026062, 'eval_auc_roc': 0.4624395777843543, 'eval_f1': 0.333843797856049, 'eval_runtime': 2.6179, 'eval_samples_per_second': 498.497, 'eval_steps_per_second': 8.022, 'epoch': 1.0, 'step': 24}, {'loss': 0.6851, 'grad_norm': 5.024822235107422, 'learning_rate': 9.972609476841368e-06, 'epoch': 2.0, 'step': 48}, {'eval_loss': 0.8118428587913513, 'eval_auc_roc': 0.6260399197658741, 'eval_f1': 0.5821236444368543, 'eval_runtime': 2.581, 'eval_samples_per_second': 505.614, 'eval_steps_per_second': 8.136, 'epoch': 2.0, 'step': 48}, {'loss': 0.6792, 'grad_norm': 7.425896167755127, 'learning_rate': 9.938441702975689e-06, 'epoch': 3.0, 'step': 72}, {'eval_loss': 0.6961158514022827, 'eval_auc_roc': 0.40913649666239194, 'eval_f1': 0.4232781355705467, 'eval_runtime': 2.6372, 'eval_samples_per_second': 494.838, 'eval_steps_per_second': 7.963, 'epoch': 3.0, 'step': 72}, {'loss': 0.6761, 'grad_norm': 6.437779426574707, 'learning_rate': 9.890738003669029e-06, 'epoch': 4.0, 'step': 96}, {'eval_loss': 0.6965627670288086, 'eval_auc_roc': 0.400884078599379, 'eval_f1': 0.41370205765867885, 'eval_runtime': 2.6248, 'eval_samples_per_second': 497.19, 'eval_steps_per_second': 8.001, 'epoch': 4.0, 'step': 96}, {'loss': 0.672, 'grad_norm': 5.762818813323975, 'learning_rate': 9.829629131445342e-06, 'epoch': 5.0, 'step': 120}, {'eval_loss': 0.6821569800376892, 'eval_auc_roc': 0.6420585596377251, 'eval_f1': 0.5416655737872718, 'eval_runtime': 2.6831, 'eval_samples_per_second': 486.381, 'eval_steps_per_second': 7.827, 'epoch': 5.0, 'step': 120}, {'loss': 0.664, 'grad_norm': 8.679765701293945, 'learning_rate': 9.755282581475769e-06, 'epoch': 6.0, 'step': 144}, {'eval_loss': 0.6659977436065674, 'eval_auc_roc': 0.6481090019119022, 'eval_f1': 0.5835167580116667, 'eval_runtime': 2.6903, 'eval_samples_per_second': 485.074, 'eval_steps_per_second': 7.806, 'epoch': 6.0, 'step': 144}, {'loss': 0.6617, 'grad_norm': 7.384735584259033, 'learning_rate': 9.667902132486009e-06, 'epoch': 7.0, 'step': 168}, {'eval_loss': 0.666802704334259, 'eval_auc_roc': 0.6634887752082188, 'eval_f1': 0.6044712128960952, 'eval_runtime': 2.6546, 'eval_samples_per_second': 491.607, 'eval_steps_per_second': 7.911, 'epoch': 7.0, 'step': 168}, {'loss': 0.6553, 'grad_norm': 6.0460686683654785, 'learning_rate': 9.567727288213005e-06, 'epoch': 8.0, 'step': 192}, {'eval_loss': 0.6546226143836975, 'eval_auc_roc': 0.6763248260732724, 'eval_f1': 0.6336216010487589, 'eval_runtime': 2.6366, 'eval_samples_per_second': 494.949, 'eval_steps_per_second': 7.965, 'epoch': 8.0, 'step': 192}, {'loss': 0.6495, 'grad_norm': 5.694786548614502, 'learning_rate': 9.45503262094184e-06, 'epoch': 9.0, 'step': 216}, {'eval_loss': 0.6440473198890686, 'eval_auc_roc': 0.6916952042728899, 'eval_f1': 0.6331164930227768, 'eval_runtime': 3.0602, 'eval_samples_per_second': 426.449, 'eval_steps_per_second': 6.862, 'epoch': 9.0, 'step': 216}, {'loss': 0.6423, 'grad_norm': 4.729703426361084, 'learning_rate': 9.330127018922195e-06, 'epoch': 10.0, 'step': 240}, {'eval_loss': 0.6423932909965515, 'eval_auc_roc': 0.688844966811821, 'eval_f1': 0.6190998309224564, 'eval_runtime': 2.7753, 'eval_samples_per_second': 470.218, 'eval_steps_per_second': 7.567, 'epoch': 10.0, 'step': 240}, {'loss': 0.636, 'grad_norm': 4.891008377075195, 'learning_rate': 9.193352839727122e-06, 'epoch': 11.0, 'step': 264}, {'eval_loss': 0.6323903203010559, 'eval_auc_roc': 0.7235328382117373, 'eval_f1': 0.6562591132726879, 'eval_runtime': 2.6603, 'eval_samples_per_second': 490.554, 'eval_steps_per_second': 7.894, 'epoch': 11.0, 'step': 264}, {'loss': 0.6277, 'grad_norm': 5.279565334320068, 'learning_rate': 9.045084971874738e-06, 'epoch': 12.0, 'step': 288}, {'eval_loss': 0.6328846216201782, 'eval_auc_roc': 0.7258017540645537, 'eval_f1': 0.6528442093135105, 'eval_runtime': 2.6993, 'eval_samples_per_second': 483.465, 'eval_steps_per_second': 7.78, 'epoch': 12.0, 'step': 288}, {'loss': 0.616, 'grad_norm': 5.9618706703186035, 'learning_rate': 8.885729807284855e-06, 'epoch': 13.0, 'step': 312}, {'eval_loss': 0.6144039034843445, 'eval_auc_roc': 0.7439155005002889, 'eval_f1': 0.6808760683760684, 'eval_runtime': 2.7669, 'eval_samples_per_second': 471.646, 'eval_steps_per_second': 7.59, 'epoch': 13.0, 'step': 312}, {'loss': 0.6114, 'grad_norm': 6.488900184631348, 'learning_rate': 8.715724127386971e-06, 'epoch': 14.0, 'step': 336}, {'eval_loss': 0.6059436798095703, 'eval_auc_roc': 0.7436430426960169, 'eval_f1': 0.6838811488132754, 'eval_runtime': 2.6894, 'eval_samples_per_second': 485.239, 'eval_steps_per_second': 7.808, 'epoch': 14.0, 'step': 336}, {'loss': 0.5992, 'grad_norm': 7.01383113861084, 'learning_rate': 8.535533905932739e-06, 'epoch': 15.0, 'step': 360}, {'eval_loss': 0.609643816947937, 'eval_auc_roc': 0.7541632022247589, 'eval_f1': 0.6733792894477691, 'eval_runtime': 2.6524, 'eval_samples_per_second': 492.001, 'eval_steps_per_second': 7.917, 'epoch': 15.0, 'step': 360}, {'loss': 0.5899, 'grad_norm': 5.714977741241455, 'learning_rate': 8.345653031794292e-06, 'epoch': 16.0, 'step': 384}, {'eval_loss': 0.5811578631401062, 'eval_auc_roc': 0.7915897443124433, 'eval_f1': 0.719447440297359, 'eval_runtime': 2.6475, 'eval_samples_per_second': 492.918, 'eval_steps_per_second': 7.932, 'epoch': 16.0, 'step': 384}, {'loss': 0.5801, 'grad_norm': 4.837045669555664, 'learning_rate': 8.146601955249187e-06, 'epoch': 17.0, 'step': 408}, {'eval_loss': 0.5785623788833618, 'eval_auc_roc': 0.7827407376090418, 'eval_f1': 0.6980808238414729, 'eval_runtime': 2.6885, 'eval_samples_per_second': 485.395, 'eval_steps_per_second': 7.811, 'epoch': 17.0, 'step': 408}, {'loss': 0.5709, 'grad_norm': 9.232382774353027, 'learning_rate': 7.938926261462366e-06, 'epoch': 18.0, 'step': 432}, {'eval_loss': 0.5535686612129211, 'eval_auc_roc': 0.8307625999990605, 'eval_f1': 0.7655160021984526, 'eval_runtime': 3.0654, 'eval_samples_per_second': 425.716, 'eval_steps_per_second': 6.851, 'epoch': 18.0, 'step': 432}, {'loss': 0.5561, 'grad_norm': 5.02312707901001, 'learning_rate': 7.723195175075136e-06, 'epoch': 19.0, 'step': 456}, {'eval_loss': 0.5416608452796936, 'eval_auc_roc': 0.8253897790743011, 'eval_f1': 0.7500117522623104, 'eval_runtime': 2.7049, 'eval_samples_per_second': 482.454, 'eval_steps_per_second': 7.764, 'epoch': 19.0, 'step': 456}, {'loss': 0.5476, 'grad_norm': 5.650139808654785, 'learning_rate': 7.500000000000001e-06, 'epoch': 20.0, 'step': 480}, {'eval_loss': 0.5288419127464294, 'eval_auc_roc': 0.8450184848527553, 'eval_f1': 0.768673895779761, 'eval_runtime': 2.7665, 'eval_samples_per_second': 471.714, 'eval_steps_per_second': 7.591, 'epoch': 20.0, 'step': 480}, {'loss': 0.5355, 'grad_norm': 9.351288795471191, 'learning_rate': 7.269952498697734e-06, 'epoch': 21.0, 'step': 504}, {'eval_loss': 0.5162293314933777, 'eval_auc_roc': 0.8558052302503324, 'eval_f1': 0.7714048999881642, 'eval_runtime': 2.6744, 'eval_samples_per_second': 487.967, 'eval_steps_per_second': 7.852, 'epoch': 21.0, 'step': 504}, {'loss': 0.5188, 'grad_norm': 9.206459045410156, 'learning_rate': 7.033683215379002e-06, 'epoch': 22.0, 'step': 528}, {'eval_loss': 0.493134081363678, 'eval_auc_roc': 0.8812295363050026, 'eval_f1': 0.7991052542516288, 'eval_runtime': 2.7346, 'eval_samples_per_second': 477.218, 'eval_steps_per_second': 7.679, 'epoch': 22.0, 'step': 528}, {'loss': 0.5209, 'grad_norm': 6.064853668212891, 'learning_rate': 6.7918397477265e-06, 'epoch': 23.0, 'step': 552}, {'eval_loss': 0.5270023345947266, 'eval_auc_roc': 0.8655232833983943, 'eval_f1': 0.7639032935853274, 'eval_runtime': 2.9193, 'eval_samples_per_second': 447.029, 'eval_steps_per_second': 7.194, 'epoch': 23.0, 'step': 552}, {'loss': 0.509, 'grad_norm': 7.858725070953369, 'learning_rate': 6.545084971874738e-06, 'epoch': 24.0, 'step': 576}, {'eval_loss': 0.48649388551712036, 'eval_auc_roc': 0.8731027776603391, 'eval_f1': 0.7838207959554349, 'eval_runtime': 2.809, 'eval_samples_per_second': 464.578, 'eval_steps_per_second': 7.476, 'epoch': 24.0, 'step': 576}, {'loss': 0.4969, 'grad_norm': 7.455775737762451, 'learning_rate': 6.294095225512604e-06, 'epoch': 25.0, 'step': 600}, {'eval_loss': 0.4715055227279663, 'eval_auc_roc': 0.8858683653001498, 'eval_f1': 0.7919300547847286, 'eval_runtime': 2.6073, 'eval_samples_per_second': 500.524, 'eval_steps_per_second': 8.054, 'epoch': 25.0, 'step': 600}, {'loss': 0.4892, 'grad_norm': 9.091889381408691, 'learning_rate': 6.039558454088796e-06, 'epoch': 26.0, 'step': 624}, {'eval_loss': 0.5014130473136902, 'eval_auc_roc': 0.8645814249543162, 'eval_f1': 0.7583658766496095, 'eval_runtime': 2.6372, 'eval_samples_per_second': 494.85, 'eval_steps_per_second': 7.963, 'epoch': 26.0, 'step': 624}, {'loss': 0.4807, 'grad_norm': 13.503910064697266, 'learning_rate': 5.782172325201155e-06, 'epoch': 27.0, 'step': 648}, {'eval_loss': 0.4563937783241272, 'eval_auc_roc': 0.9070073328729736, 'eval_f1': 0.8434574603204471, 'eval_runtime': 3.0248, 'eval_samples_per_second': 431.427, 'eval_steps_per_second': 6.943, 'epoch': 27.0, 'step': 648}, {'loss': 0.4648, 'grad_norm': 11.856696128845215, 'learning_rate': 5.522642316338268e-06, 'epoch': 28.0, 'step': 672}, {'eval_loss': 0.433381587266922, 'eval_auc_roc': 0.9074747389337504, 'eval_f1': 0.8210254813473665, 'eval_runtime': 2.6324, 'eval_samples_per_second': 495.739, 'eval_steps_per_second': 7.977, 'epoch': 28.0, 'step': 672}, {'loss': 0.4529, 'grad_norm': 6.23998498916626, 'learning_rate': 5.2616797812147205e-06, 'epoch': 29.0, 'step': 696}, {'eval_loss': 0.4229833483695984, 'eval_auc_roc': 0.9059832673327791, 'eval_f1': 0.8294081485564082, 'eval_runtime': 2.6073, 'eval_samples_per_second': 500.521, 'eval_steps_per_second': 8.054, 'epoch': 29.0, 'step': 696}, {'loss': 0.4443, 'grad_norm': 13.719828605651855, 'learning_rate': 5e-06, 'epoch': 30.0, 'step': 720}, {'eval_loss': 0.44728976488113403, 'eval_auc_roc': 0.9174734705956961, 'eval_f1': 0.8377344881171472, 'eval_runtime': 2.6378, 'eval_samples_per_second': 494.728, 'eval_steps_per_second': 7.961, 'epoch': 30.0, 'step': 720}, {'loss': 0.4421, 'grad_norm': 7.833449840545654, 'learning_rate': 4.738320218785281e-06, 'epoch': 31.0, 'step': 744}, {'eval_loss': 0.41328760981559753, 'eval_auc_roc': 0.9107771154234605, 'eval_f1': 0.8411461166404492, 'eval_runtime': 2.65, 'eval_samples_per_second': 492.451, 'eval_steps_per_second': 7.924, 'epoch': 31.0, 'step': 744}, {'loss': 0.4293, 'grad_norm': 10.507028579711914, 'learning_rate': 4.477357683661734e-06, 'epoch': 32.0, 'step': 768}, {'eval_loss': 0.39238548278808594, 'eval_auc_roc': 0.9305091672656042, 'eval_f1': 0.8620552765471654, 'eval_runtime': 2.6305, 'eval_samples_per_second': 496.112, 'eval_steps_per_second': 7.983, 'epoch': 32.0, 'step': 768}, {'loss': 0.4198, 'grad_norm': 6.526033878326416, 'learning_rate': 4.217827674798845e-06, 'epoch': 33.0, 'step': 792}, {'eval_loss': 0.41052013635635376, 'eval_auc_roc': 0.9285714285714286, 'eval_f1': 0.8494795516281961, 'eval_runtime': 2.7274, 'eval_samples_per_second': 478.472, 'eval_steps_per_second': 7.7, 'epoch': 33.0, 'step': 792}, {'loss': 0.4137, 'grad_norm': 11.323596954345703, 'learning_rate': 3.960441545911205e-06, 'epoch': 34.0, 'step': 816}, {'eval_loss': 0.4001311957836151, 'eval_auc_roc': 0.9256519022722042, 'eval_f1': 0.853473275060858, 'eval_runtime': 2.6095, 'eval_samples_per_second': 500.097, 'eval_steps_per_second': 8.048, 'epoch': 34.0, 'step': 816}, {'loss': 0.4118, 'grad_norm': 10.7763671875, 'learning_rate': 3.705904774487396e-06, 'epoch': 35.0, 'step': 840}, {'eval_loss': 0.38966938853263855, 'eval_auc_roc': 0.934833260521334, 'eval_f1': 0.8680814150304671, 'eval_runtime': 2.6305, 'eval_samples_per_second': 496.104, 'eval_steps_per_second': 7.983, 'epoch': 35.0, 'step': 840}, {'loss': 0.407, 'grad_norm': 11.056724548339844, 'learning_rate': 3.4549150281252635e-06, 'epoch': 36.0, 'step': 864}, {'eval_loss': 0.38337230682373047, 'eval_auc_roc': 0.9286395430224965, 'eval_f1': 0.8369353764157228, 'eval_runtime': 3.0125, 'eval_samples_per_second': 433.191, 'eval_steps_per_second': 6.971, 'epoch': 36.0, 'step': 864}, {'loss': 0.3953, 'grad_norm': 12.346797943115234, 'learning_rate': 3.2081602522734987e-06, 'epoch': 37.0, 'step': 888}, {'eval_loss': 0.362457275390625, 'eval_auc_roc': 0.937076339858228, 'eval_f1': 0.861932683807625, 'eval_runtime': 2.6245, 'eval_samples_per_second': 497.237, 'eval_steps_per_second': 8.002, 'epoch': 37.0, 'step': 888}, {'loss': 0.3918, 'grad_norm': 7.145956039428711, 'learning_rate': 2.966316784621e-06, 'epoch': 38.0, 'step': 912}, {'eval_loss': 0.35128721594810486, 'eval_auc_roc': 0.9414051306623072, 'eval_f1': 0.8585365853658536, 'eval_runtime': 2.6176, 'eval_samples_per_second': 498.543, 'eval_steps_per_second': 8.023, 'epoch': 38.0, 'step': 912}, {'loss': 0.3799, 'grad_norm': 9.467170715332031, 'learning_rate': 2.7300475013022666e-06, 'epoch': 39.0, 'step': 936}, {'eval_loss': 0.34386515617370605, 'eval_auc_roc': 0.9397774301591999, 'eval_f1': 0.8680423280423282, 'eval_runtime': 2.6429, 'eval_samples_per_second': 493.776, 'eval_steps_per_second': 7.946, 'epoch': 39.0, 'step': 936}, {'loss': 0.3928, 'grad_norm': 8.009054183959961, 'learning_rate': 2.5000000000000015e-06, 'epoch': 40.0, 'step': 960}, {'eval_loss': 0.34720996022224426, 'eval_auc_roc': 0.9414192233073558, 'eval_f1': 0.8631965907805963, 'eval_runtime': 2.6675, 'eval_samples_per_second': 489.221, 'eval_steps_per_second': 7.873, 'epoch': 40.0, 'step': 960}, {'loss': 0.3756, 'grad_norm': 8.383503913879395, 'learning_rate': 2.2768048249248648e-06, 'epoch': 41.0, 'step': 984}, {'eval_loss': 0.34713131189346313, 'eval_auc_roc': 0.9376423944343448, 'eval_f1': 0.8718111603432486, 'eval_runtime': 2.694, 'eval_samples_per_second': 484.414, 'eval_steps_per_second': 7.795, 'epoch': 41.0, 'step': 984}, {'loss': 0.3768, 'grad_norm': 12.955114364624023, 'learning_rate': 2.061073738537635e-06, 'epoch': 42.0, 'step': 1008}, {'eval_loss': 0.3362712562084198, 'eval_auc_roc': 0.9438760410941529, 'eval_f1': 0.8733463560277606, 'eval_runtime': 2.6609, 'eval_samples_per_second': 490.438, 'eval_steps_per_second': 7.892, 'epoch': 42.0, 'step': 1008}, {'loss': 0.3728, 'grad_norm': 8.99167251586914, 'learning_rate': 1.8533980447508138e-06, 'epoch': 43.0, 'step': 1032}, {'eval_loss': 0.33472511172294617, 'eval_auc_roc': 0.9470468862300766, 'eval_f1': 0.8811252593911192, 'eval_runtime': 2.6906, 'eval_samples_per_second': 485.015, 'eval_steps_per_second': 7.805, 'epoch': 43.0, 'step': 1032}, {'loss': 0.3699, 'grad_norm': 6.7088541984558105, 'learning_rate': 1.6543469682057105e-06, 'epoch': 44.0, 'step': 1056}, {'eval_loss': 0.3293633460998535, 'eval_auc_roc': 0.9466969188780375, 'eval_f1': 0.8662008513366362, 'eval_runtime': 2.6323, 'eval_samples_per_second': 495.764, 'eval_steps_per_second': 7.978, 'epoch': 44.0, 'step': 1056}, {'loss': 0.3643, 'grad_norm': 12.335562705993652, 'learning_rate': 1.4644660940672628e-06, 'epoch': 45.0, 'step': 1080}, {'eval_loss': 0.3337670564651489, 'eval_auc_roc': 0.9476411260962904, 'eval_f1': 0.8606977115866739, 'eval_runtime': 3.2059, 'eval_samples_per_second': 407.062, 'eval_steps_per_second': 6.55, 'epoch': 45.0, 'step': 1080}, {'loss': 0.3821, 'grad_norm': 8.062496185302734, 'learning_rate': 1.2842758726130283e-06, 'epoch': 46.0, 'step': 1104}, {'eval_loss': 0.3365749716758728, 'eval_auc_roc': 0.9452265862446388, 'eval_f1': 0.860548031094415, 'eval_runtime': 2.6199, 'eval_samples_per_second': 498.113, 'eval_steps_per_second': 8.016, 'epoch': 46.0, 'step': 1104}, {'loss': 0.3653, 'grad_norm': 7.057847023010254, 'learning_rate': 1.1142701927151456e-06, 'epoch': 47.0, 'step': 1128}, {'eval_loss': 0.33057183027267456, 'eval_auc_roc': 0.9476317309995913, 'eval_f1': 0.8779519430812965, 'eval_runtime': 2.6252, 'eval_samples_per_second': 497.101, 'eval_steps_per_second': 7.999, 'epoch': 47.0, 'step': 1128}, {'loss': 0.3543, 'grad_norm': 10.305461883544922, 'learning_rate': 9.549150281252633e-07, 'epoch': 48.0, 'step': 1152}, {'eval_loss': 0.3188188970088959, 'eval_auc_roc': 0.9476857528056107, 'eval_f1': 0.8795021645912743, 'eval_runtime': 2.6397, 'eval_samples_per_second': 494.381, 'eval_steps_per_second': 7.956, 'epoch': 48.0, 'step': 1152}, {'loss': 0.3649, 'grad_norm': 17.125205993652344, 'learning_rate': 8.066471602728804e-07, 'epoch': 49.0, 'step': 1176}, {'eval_loss': 0.3205323815345764, 'eval_auc_roc': 0.9475777091935719, 'eval_f1': 0.8881115020882564, 'eval_runtime': 2.7498, 'eval_samples_per_second': 474.584, 'eval_steps_per_second': 7.637, 'epoch': 49.0, 'step': 1176}, {'loss': 0.3575, 'grad_norm': 9.929656028747559, 'learning_rate': 6.698729810778065e-07, 'epoch': 50.0, 'step': 1200}, {'eval_loss': 0.31579282879829407, 'eval_auc_roc': 0.9494449846625047, 'eval_f1': 0.8919540229885057, 'eval_runtime': 2.6127, 'eval_samples_per_second': 499.478, 'eval_steps_per_second': 8.038, 'epoch': 50.0, 'step': 1200}, {'loss': 0.3556, 'grad_norm': 7.937897205352783, 'learning_rate': 5.449673790581611e-07, 'epoch': 51.0, 'step': 1224}, {'eval_loss': 0.3128263056278229, 'eval_auc_roc': 0.9505160256861943, 'eval_f1': 0.8865260060726271, 'eval_runtime': 2.6134, 'eval_samples_per_second': 499.349, 'eval_steps_per_second': 8.036, 'epoch': 51.0, 'step': 1224}, {'loss': 0.3547, 'grad_norm': 9.611106872558594, 'learning_rate': 4.322727117869951e-07, 'epoch': 52.0, 'step': 1248}, {'eval_loss': 0.31994324922561646, 'eval_auc_roc': 0.9486370063463878, 'eval_f1': 0.8787830687830688, 'eval_runtime': 2.6182, 'eval_samples_per_second': 498.431, 'eval_steps_per_second': 8.021, 'epoch': 52.0, 'step': 1248}, {'loss': 0.3647, 'grad_norm': 8.251773834228516, 'learning_rate': 3.320978675139919e-07, 'epoch': 53.0, 'step': 1272}, {'eval_loss': 0.33219751715660095, 'eval_auc_roc': 0.946642897072018, 'eval_f1': 0.8676108374384237, 'eval_runtime': 2.7334, 'eval_samples_per_second': 477.42, 'eval_steps_per_second': 7.683, 'epoch': 53.0, 'step': 1272}, {'loss': 0.3682, 'grad_norm': 7.654757022857666, 'learning_rate': 2.447174185242324e-07, 'epoch': 54.0, 'step': 1296}, {'eval_loss': 0.3153829276561737, 'eval_auc_roc': 0.9487967229902713, 'eval_f1': 0.8779197734136395, 'eval_runtime': 3.0356, 'eval_samples_per_second': 429.893, 'eval_steps_per_second': 6.918, 'epoch': 54.0, 'step': 1296}, {'loss': 0.3646, 'grad_norm': 5.869446277618408, 'learning_rate': 1.7037086855465902e-07, 'epoch': 55.0, 'step': 1320}, {'eval_loss': 0.3262905478477478, 'eval_auc_roc': 0.9490010663434754, 'eval_f1': 0.8613341204250295, 'eval_runtime': 2.6238, 'eval_samples_per_second': 497.364, 'eval_steps_per_second': 8.004, 'epoch': 55.0, 'step': 1320}, {'loss': 0.3531, 'grad_norm': 7.8233113288879395, 'learning_rate': 1.0926199633097156e-07, 'epoch': 56.0, 'step': 1344}, {'eval_loss': 0.3172907829284668, 'eval_auc_roc': 0.9493134533087182, 'eval_f1': 0.8842215721377367, 'eval_runtime': 2.6406, 'eval_samples_per_second': 494.214, 'eval_steps_per_second': 7.953, 'epoch': 56.0, 'step': 1344}, {'loss': 0.3557, 'grad_norm': 6.671437740325928, 'learning_rate': 6.15582970243117e-08, 'epoch': 57.0, 'step': 1368}, {'eval_loss': 0.3124620020389557, 'eval_auc_roc': 0.9506710447817284, 'eval_f1': 0.8888573021148977, 'eval_runtime': 2.6432, 'eval_samples_per_second': 493.717, 'eval_steps_per_second': 7.945, 'epoch': 57.0, 'step': 1368}, {'loss': 0.3663, 'grad_norm': 9.246814727783203, 'learning_rate': 2.7390523158633552e-08, 'epoch': 58.0, 'step': 1392}, {'eval_loss': 0.31977638602256775, 'eval_auc_roc': 0.948430314219009, 'eval_f1': 0.8896317770270588, 'eval_runtime': 2.6643, 'eval_samples_per_second': 489.803, 'eval_steps_per_second': 7.882, 'epoch': 58.0, 'step': 1392}, {'loss': 0.3548, 'grad_norm': 6.993964672088623, 'learning_rate': 6.852326227130835e-09, 'epoch': 59.0, 'step': 1416}, {'eval_loss': 0.3158820569515228, 'eval_auc_roc': 0.9498748103364855, 'eval_f1': 0.8887736802289595, 'eval_runtime': 2.6287, 'eval_samples_per_second': 496.437, 'eval_steps_per_second': 7.989, 'epoch': 59.0, 'step': 1416}, {'loss': 0.3523, 'grad_norm': 11.411174774169922, 'learning_rate': 0.0, 'epoch': 60.0, 'step': 1440}, {'eval_loss': 0.32037484645843506, 'eval_auc_roc': 0.9491067611813394, 'eval_f1': 0.87323898887894, 'eval_runtime': 2.7161, 'eval_samples_per_second': 480.467, 'eval_steps_per_second': 7.732, 'epoch': 60.0, 'step': 1440}, {'train_runtime': 1330.0961, 'train_samples_per_second': 137.358, 'train_steps_per_second': 1.083, 'total_flos': 515666599056000.0, 'train_loss': 0.48136232362853154, 'epoch': 60.0, 'step': 1440}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import get_scheduler\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"Was asked to gather along dimension 0, but all input tensors were scalars\",\n",
    "    category=UserWarning\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./WhartonDS_ClsModel_Test\",\n",
    "    learning_rate = 1e-5,\n",
    "    eval_strategy=\"epoch\",  # Evaluate at each epoch\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",  # Log every epoch\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=1,  # Log at every step\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=60,\n",
    "    weight_decay=0.0005,\n",
    "    report_to=\"none\",\n",
    "    push_to_hub=True,\n",
    "    optim = 'adamw_torch',\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    hub_model_id=\"KanWasTaken/WhartonDS_ClsModel\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_auc_roc\",\n",
    "    greater_is_better= True,\n",
    "    save_total_limit = 1\n",
    ")\n",
    "\n",
    "# Initialize Model\n",
    "model = FeatureGroupingModel(FeatureGroupingConfig())\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=train_set,\n",
    "    eval_dataset=val_set,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train the Model\n",
    "trainer.train()\n",
    "\n",
    "# Save Model\n",
    "trainer.save_model(\"./WhartonDS_ClsModel\")\n",
    "\n",
    "# Save Model to Hugging Face Hub\n",
    "trainer.push_to_hub(\"KanWasTaken/WhartonDS_ClsModel\")\n",
    "\n",
    "print(trainer.state.log_history)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6675244,
     "sourceId": 10761395,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1399.456487,
   "end_time": "2025-02-18T18:11:56.930857",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-18T17:48:37.474370",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2132b5d6a3474a8d8c8fc60e8ae4e006": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e8373483fefe49e095da29b8114bfb3d",
        "IPY_MODEL_c6f53b8500454ca1b0d2b520e38b1214",
        "IPY_MODEL_cf5b85f9a1e14414b7bfa0cb67113324"
       ],
       "layout": "IPY_MODEL_d7df2b025a30471688571d658755df2a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "4baf39e5bf294fcab29ed0d1a8b45c21": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4e280f0828e54255bc2cd98df1520a0e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "57d1a68f8a894d69aacf3d2b1f754d63": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "584026e5ffc948bc9369727e125072dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e7eb44cefdf6440fba45e84b03249362",
       "max": 102469840.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4baf39e5bf294fcab29ed0d1a8b45c21",
       "tabbable": null,
       "tooltip": null,
       "value": 102469840.0
      }
     },
     "58d44d1d61f64dd48db4ef951435018d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5f87df596a444e42b17194cf24e29679": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_feb778d38dbf494781107a11209d9e4f",
       "placeholder": "​",
       "style": "IPY_MODEL_57d1a68f8a894d69aacf3d2b1f754d63",
       "tabbable": null,
       "tooltip": null,
       "value": " 102M/102M [00:00&lt;00:00, 203MB/s]"
      }
     },
     "6ab9ffc33efc4115bc90c670eb060030": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d847b964849a4dcd8534419fda4be451",
       "placeholder": "​",
       "style": "IPY_MODEL_58d44d1d61f64dd48db4ef951435018d",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "729a07d5b1ef4983988cbbd566717ba8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "74a27b7cfed548dbaf20637ce9a1c8d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a0ebc80ab30d40039018457b4cec4b44": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a24b5845736a47c5a4ef699d0c392eed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "a487ebaaf8d342cb9fd37765d1292d82": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c6f53b8500454ca1b0d2b520e38b1214": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a24b5845736a47c5a4ef699d0c392eed",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4e280f0828e54255bc2cd98df1520a0e",
       "tabbable": null,
       "tooltip": null,
       "value": 0.0
      }
     },
     "cf5b85f9a1e14414b7bfa0cb67113324": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_729a07d5b1ef4983988cbbd566717ba8",
       "placeholder": "​",
       "style": "IPY_MODEL_a0ebc80ab30d40039018457b4cec4b44",
       "tabbable": null,
       "tooltip": null,
       "value": " 0/0 [00:00&lt;?, ?it/s]"
      }
     },
     "cf9c072638f74ac1a339e75c78e5bd39": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6ab9ffc33efc4115bc90c670eb060030",
        "IPY_MODEL_584026e5ffc948bc9369727e125072dd",
        "IPY_MODEL_5f87df596a444e42b17194cf24e29679"
       ],
       "layout": "IPY_MODEL_a487ebaaf8d342cb9fd37765d1292d82",
       "tabbable": null,
       "tooltip": null
      }
     },
     "d7df2b025a30471688571d658755df2a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d847b964849a4dcd8534419fda4be451": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e7eb44cefdf6440fba45e84b03249362": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e8373483fefe49e095da29b8114bfb3d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f5a536f5de5647afb68b3185e816b700",
       "placeholder": "​",
       "style": "IPY_MODEL_74a27b7cfed548dbaf20637ce9a1c8d3",
       "tabbable": null,
       "tooltip": null,
       "value": ""
      }
     },
     "f5a536f5de5647afb68b3185e816b700": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "feb778d38dbf494781107a11209d9e4f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
